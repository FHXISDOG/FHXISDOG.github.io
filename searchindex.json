{"categories":[{"title":"docker","uri":"https://fhxisdog.github.io/categories/docker/"},{"title":"flutter","uri":"https://fhxisdog.github.io/categories/flutter/"},{"title":"Git","uri":"https://fhxisdog.github.io/categories/git/"},{"title":"jvm","uri":"https://fhxisdog.github.io/categories/jvm/"},{"title":"linux","uri":"https://fhxisdog.github.io/categories/linux/"},{"title":"nacos","uri":"https://fhxisdog.github.io/categories/nacos/"},{"title":"orther","uri":"https://fhxisdog.github.io/categories/orther/"},{"title":"skywalking","uri":"https://fhxisdog.github.io/categories/skywalking/"},{"title":"smicroservices","uri":"https://fhxisdog.github.io/categories/smicroservices/"},{"title":"spring boot","uri":"https://fhxisdog.github.io/categories/spring-boot/"}],"posts":[{"content":"基本概念 四度空间: 工作区:Workspace\n 就是你在电脑里能看到的目录\n暂存区: Index/Stage/Cached\n英文叫stage, 或index。一般存放在 \u0026ldquo;.git目录下\u0026rdquo; 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）\n版本库:Repository\n工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。\n远程仓库: Remote Repository\n远程仓库则被设置在一个能被所有团队成员访问到的远程服务器上，基本上都是在互联网上或者是本地局域网中\n五种状态: 未修改(Unmodify):\n记录在工作区,没有被修改的文件\n未追踪(Untracked):\n新增的文件的状态，未受Git管理，记录在工作区\n已修改(Modified):\n受Git管理过的文件的改动状态（包括改动内容、删除文件），记录在工作区\n已暂存(Staged):\n将记录在工作区的文件变动状态通知了Git，记录在暂存区\n已提交(Commited):\n已提交到本地仓库\n已推送(pushed):\n已推送到远程仓库\n一张图概括:  新建一个仓库 git init #在当前目录新建一个git仓库\rgit clone #clone一个远程的仓库到当前目录\r当你创建一个带有.git文件夹的目录后,这个目录中的所有操作都将会被git记录,这就故事开始的地方,让我们开启这个游戏!\n加入暂存区 这个目录就是被git记录的工作区,在这个目录下的所有增删改都会被git纳入到版本控制.\n可以使用git status查看当前目录的哪些文件的变化:\ngit status #查看当前工作区文件状态\rgit status -s #简短形式输出当前工作状态\r修改完后使用git add 加入到缓存区.\ngit add . #将当前目录所有文件做修改都加入缓存区\rgit add \u0026lt;file name\u0026gt; #将某个文件的修改就如缓存区\r如果有操作想被git忽略有3钟种方式:\n .gitignore文件  .gitignore只会忽略尚未加入版本控制的文件,如果文件已被加入版本控制,写入.gitignore文件git仍会记录文件的变化.如果已经纳入版本控制的文件想忽略,例如:在远程服务器中的配置文件,想本地修改,又不想被git记录可以使用下面两种命令\n git update-index --assume-unchanged  git update-index --assume-unchanged \u0026lt;file name\u0026gt; # 这个会关闭文件与远程仓库的跟踪，认为这个文件远程仓库是不会修改，所以每次pull都是本地的文件\r反向操作\ngit update-index --no-assume-unchanged \u0026lt;file name\u0026gt;\r git update-index --skip-worktree  git update-index --skip-worktree \u0026lt;file name\u0026gt; # 这个不会关闭文件与远程仓库的跟踪，只是告诉Git不要跟踪对本地文件/文件夹的更改，每次pull时会拉取最新的变化会提示冲突，但因为没有跟踪本地更改，所以需要no-skip-worktree再合并最新的变化 或者使用git stash将本地的更改保存起来,再git pull,然后再git stash pop,再合并冲突,比较麻烦\r反向操作:\ngit update-index --no-skip-worktree \u0026lt;file name\u0026gt;\r提交 改写提交 如果提交完发现自己漏提了文件,或者提交信息写错了可以使用--amend来改写提交\ngit commit --amend #如果有漏提的文件,add到缓存区即可,然后git会打开默认的编辑器让你重新编写提交信息\r复制提交 cherry-pick可以将其它提交复制到当前再提交一遍\n执行:\ngit cherry-pick c2 c4\r恢复 文件已被修改尚未加入到缓存区 git restore \u0026lt;file name\u0026gt; #将文件恢复到和缓存区(index)一样的状态\r文件被修改并提交到缓存区 git restore --staged \u0026lt;file name\u0026gt; #将文件从缓存区(index)移动出来 新增的文件删除(untracked状态) git clean -f \u0026lt;file name\u0026gt; #将untracked状态的文件删除\rGit指针 指针是git的精髓,理解的指针的移动对于很多命令的理解和记忆更胜一筹.\nGit中指针大致有五类:\n  HEAD\n指向当前正在操作的 commit。\n  分支指针\n指向当前分支所在的commit\n  ORIG_HEAD\n当使用一些在 Git 看来比较危险的操作去移动 HEAD 指针的时候，ORIG_HEAD 就会被创建出来，记录危险操作之前的 HEAD，方便 HEAD 的恢复，有点像修改前的备份。\n  FETCH_HEAD\n记录从远程仓库拉取的记录。\n  MERGE_HEAD\n当运行 git merge 时，MERGE_HEAD 记录你正在合并到你的分支中的提交。MERGE_HEAD在合并的时候会出现，合并结束，就删除了这个文件。\n  CHERRY_PICK_HEAD\n记录您在运行 git cherry-pick时要合并的提交。同上，这个文件只在 cherry-pick 期间存在。\n  这里我们主要理解HEAD指针和分支指针.\n正常情况下HEAD指针是指向当前分支指针,如图:\ngit checkout \u0026lt;commit id\u0026gt; git checkout 本质就是移动HEAD指针 (个人理解,待验证)\n当执行git checkout \u0026lt;commit id\u0026gt; 或 git checkout HEAD^时,进入指针分离模式,HEAD指针指向一条commit id,不再指向分支指针,此时如果提交代码,只有HEAD指针会指向新提交的commit id,而分支指针不会移动.\n此时如果想让HEAD重新指向分支指针,执行git checkout \u0026lt;branch name\u0026gt;即可.\ngit reset reset 的本质：移动 HEAD 以及它所指向的 branch\n实质上，reset 这个指令虽然可以用来撤销 commit ，但它的实质行为并不是撤销，而是移动 HEAD ，并且「捎带」上 HEAD 所指向的 branch（如果有的话）。也就是说，reset 这个指令的行为其实和它的字面意思 \u0026ldquo;reset\u0026rdquo;（重置）十分相符：它是用来重置 HEAD 以及它所指向的 branch 的位置的。\n而 reset --hard HEAD^ 之所以起到了撤销 commit 的效果，是因为它把 HEAD 和它所指向的 branch 一起移动到了当前 commit 的父 commit 上，从而起到了「撤销」的效果：\n git reset 各个选项解释:\n \u0026ndash;soft – 缓存区和工作目录都不会被改变 \u0026ndash;mixed – 默认选项。缓存区和你指定的提交同步，但工作目录不受影响 \u0026ndash;hard – 缓存区和工作目录都同步到你指定的提交  把这些标记想成定义 git reset 操作的作用域就容易理解多了。\n git branch -f \u0026lt;branch name\u0026gt;  这条命令是将分支指针移动到指定位置.运行git branch -f master c1:\n匿名分支与头指针分离处理  匿名分支  当git进入头指针分离状态,进行提交会产生一个匿名分支,如果一直匿名分支,就会被git清理掉,\n可以使用`git branch ``起个名字,来避免这种情况.\n 强制回退丢失 commit id  如果意外使用如:git reset --hard HEAD^时,可能会使commit消失,这时候可以使用git reflog来找回命令\n分支  几乎所有的版本控制系统都以某种形式支持分支。 使用分支意味着你可以把你的工作从开发主线上分离开来，以免影响开发主线。 在很多版本控制系统中，这是一个略微低效的过程——常常需要完全创建一个源代码目录的副本。对于大项目来说，这样的过程会耗费很多时间。\n有人把 Git 的分支模型称为它的“必杀技特性”，也正因为这一特性，使得 Git 从众多版本控制系统中脱颖而出。 为何 Git 的分支模型如此出众呢？ Git 处理分支的方式可谓是难以置信的轻量，创建新分支这一操作几乎能在瞬间完成，并且在不同分支之间的切换操作也是一样便捷。 与许多其它版本控制系统不同，Git 鼓励在工作流程中频繁地使用分支与合并，哪怕一天之内进行许多次。 理解和精通这一特性，你便会意识到 Git 是如此的强大而又独特，并且从此真正改变你的开发方式。\n 命令 git branch #列出仓库中所有分支。\rgit branch \u0026lt;branch\u0026gt; #创建一个名为 \u0026lt;branch\u0026gt; 的分支。不会 自动切换到那个分支去。\rgit branch -d \u0026lt;branch\u0026gt; #删除指定分支。这是一个安全的操作，Git 会阻止你删除包含未合并更改的分支。\rgit branch -D \u0026lt;branch\u0026gt; #强制删除指定分支，即使包含未合并更改。如果你希望永远删除某条开发线的所有提交，你应该用这个命令。\rgit branch -m \u0026lt;branch\u0026gt; #将当前分支命名为 \u0026lt;branch\u0026gt;。\rgit checkout \u0026lt;existing-branch\u0026gt; #查看特定分支，分支应该已经通过 git branch 创建。这使得 \u0026lt;existing-branch\u0026gt; 成为当前的分支，并更新工作目录的版本。\rgit checkout -b \u0026lt;new-branch\u0026gt; #创建并查看 \u0026lt;new-branch\u0026gt;，-b 选项是一个方便的标记，告诉Git在运行 git checkout \u0026lt;new-branch\u0026gt; 之前运行 git branch \u0026lt;new-branch\u0026gt;。\rgit checkout -b \u0026lt;new-branch\u0026gt; \u0026lt;existing-branch\u0026gt; #和上一条相同，但将 \u0026lt;existing-branch\u0026gt; 作为新分支的基，而不是当前分支。\r分支合并的两种姿势 git merge merge的三种特殊情况   冲突\nmerge 在做合并的时候，是有一定的自动合并能力的：如果一个分支改了 A 文件，另一个分支改了 B 文件，那么合并后就是既改 A 也改 B，这个动作会自动完成；如果两个分支都改了同一个文件，但一个改的是第 1 行，另一个改的是第 2 行，那么合并后就是第 1 行和第 2 行都改，也是自动完成。\n  但，如果两个分支修改了同一部分内容，merge 的自动算法就搞不定了。这种情况 Git 称之为：冲突（Conflict）。\n解决方法:\n 解决掉冲突 手动 commit 一下  或者放弃合并:\ngit merge --abort\r  HEAD 领先于目标 commit\n如果 merge 时的目标 commit 和 HEAD 处的 commit 并不存在分叉，而是 HEAD 领先于目标 commit：\n  那么 merge 就没必要再创建一个新的 commit 来进行合并操作，因为并没有什么需要合并的。在这种情况下， Git 什么也不会做，merge 是一个空操作。\n  HEAD 落后于 目标 commit——fast-forward\n而另一种情况：如果 HEAD 和目标 commit 依然是不存在分叉，但 HEAD 不是领先于目标 commit，而是落后于目标 commit.\n那么 Git 会直接把 HEAD（以及它所指向的 branch，如果有的话）移动到目标 commit\n  git rebase rebase 的意思是，给你的 commit 序列重新设置基础点（也就是父 commit）。展开来说就是，把你指定的 commit 以及它所在的 commit 串，以指定的目标 commit 为基础，依次重新提交一次。例如下面这个 merge：\ngit merge branch1\r如果把 merge 换成 rebase，可以这样操作：\ngit checkout branch1\rgit rebase master\r另外，在 rebase 之后，记得切回 master 再 merge 一下，把 master 移到最新的 commit：\ngit checkout master\rgit merge branch1\r 为什么要从 branch1 来 rebase，然后再切回 master 再 merge 一下这么麻烦，而不是直接在 master 上执行 rebase？\n从图中可以看出，rebase 后的 commit 虽然内容和 rebase 之前相同，但它们已经是不同的 commits 了。如果直接从 master 执行 rebase 的话，就会是下面这样：\n这就导致 master 上之前的两个最新 commit 被剔除了。如果这两个 commit 之前已经在中央仓库存在，这就会导致没法 push 了：\n 它会把整个 branch1分支移动到 master 分支的后面，有效地把所有 master 分支上新的提交并入过来。但是，rebase 为原分支上每一个提交创建一个新的提交，重写了项目历史，并且不会带来合并提交。\nrebase最大的好处是你的项目历史会非常整洁。首先，它不像 git merge 那样引入不必要的合并提交。其次，如上图所示，rebase 导致最后的项目历史呈现出完美的线性——你可以从项目终点到起点浏览而不需要任何的 fork。这让你更容易使用 git log、git bisect 和 gitk 来查看项目历史。\n不过，这种简单的提交历史会带来两个后果：安全性和可跟踪性。如果你违反了 rebase 黄金法则，重写项目历史可能会给你的协作工作流带来灾难性的影响。此外，rebase 不会有合并提交中附带的信息——你看不到 branch分支中并入了上游的哪些更改。\n交互式rebase 交互式的 rebase 允许你更改并入新分支的提交。这比自动的 rebase 更加强大，因为它提供了对分支上提交历史完整的控制。一般来说，这被用于将 feature 分支并入 master 分支之前，清理混乱的历史。\n把 -i 传入 git rebase 选项来开始一个交互式的rebase过程：\ngit checkout feature\rgit rebase -i master\r它会打开一个文本编辑器，显示所有将被移动的提交：\npick 33d5b7a Message for commit #1\rpick 9480b3d Message for commit #2\rpick 5c67e61 Message for commit #3\r这个列表定义了 rebase 将被执行后分支会是什么样的。更改 pick 命令或者重新排序，这个分支的历史就能如你所愿了。比如说，如果第二个提交修复了第一个提交中的小问题，你可以用 fixup 命令把它们合到一个提交中：\npick 33d5b7a Message for commit #1\rfixup 9480b3d Message for commit #2\rpick 5c67e61 Message for commit #3\r忽略不重要的提交会让你的 feature 分支的历史更清晰易读。这是 git merge 做不到的。\nRebase的黄金法则 当你理解 rebase 是什么的时候，最重要的就是什么时候 不能 用 rebase。git rebase 的黄金法则便是，绝不要在公共的分支上使用它。\n这次 rebase 将 master 分支上的所有提交都移到了 feature 分支后面。问题是它只发生在你的代码仓库中，其他所有的开发者还在原来的 master 上工作。因为 rebase 引起了新的提交，Git 会认为你的 master 分支和其他人的 master 已经分叉了。\n同步两个 master 分支的唯一办法是把它们 merge 到一起，导致一个额外的合并提交和两堆包含同样更改的提交。不用说，这会让人非常困惑。\n所以，在你运行 git rebase 之前，一定要问问你自己「有没有别人正在这个分支上工作？」。如果答案是肯定的，那么把你的爪子放回去，重新找到一个无害的方式（如 git revert）来提交你的更改。不然的话，你可以随心所欲地重写历史。\n强制推送 如果你想把 rebase 之后的 master 分支推送到远程仓库，Git 会阻止你这么做，因为两个分支包含冲突。但你可以传入 --force 标记来强行推送。就像下面一样：\n# 小心使用这个命令！\rgit push --force\r它会重写远程的 master 分支来匹配你仓库中 rebase 之后的 master 分支，对于团队中其他成员来说这看上去很诡异。所以，务必小心这个命令，只有当你知道你在做什么的时候再使用。\n仅有的几个强制推送的使用场景之一是，当你在想向远程仓库推送了一个私有分支之后，执行了一个本地的清理（比如说为了回滚）。这就像是在说「哦，其实我并不想推送之前那个 feature 分支的。用我现在的版本替换掉吧。」同样，你要注意没有别人正在这个 feature 分支上工作。\n本地清理 在你工作流中使用 rebase 最好的用法之一就是清理本地正在开发的分支。隔一段时间执行一次交互式 rebase，你可以保证你 feature 分支中的每一个提交都是专注和有意义的。你在写代码时不用担心造成孤立的提交——因为你后面一定能修复。\n调用 git rebase 的时候，你有两个基（base）可以选择：上游分支（比如 master）或者你 feature 分支中早先的一个提交。我们在「交互式 rebase」一节看到了第一种的例子。后一种在当你只需要修改最新几次提交时也很有用。比如说，下面的命令对最新的 3 次提交进行了交互式 rebase：\ngit checkout feature\rgit rebase -i HEAD~3\r通过指定 HEAD~3 作为新的基提交，你实际上没有移动分支——你只是将之后的 3 次提交重写了。注意它不会把上游分支的更改并入到 feature 分支中。\n如果你想用这个方法重写整个 feature 分支，git merge-base 命令非常方便地找出 feature 分支开始分叉的基。下面这段命令返回基提交的 ID，你可以接下来将它传给 git rebase：\ngit merge-base feature master\r交互式 rebase 是在你工作流中引入 git rebase 的的好办法，因为它只影响本地分支。其他开发者只能看到你已经完成的结果，那就是一个非常整洁、易于追踪的分支历史。\n但同样的，这只能用在私有分支上。如果你在同一个 feature 分支和其他开发者合作的话，这个分支是公开的，你不能重写这个历史。\n用带有交互式的 rebase 清理本地提交，这是无法用 git merge 命令代替的。\n保存当前工作状态  此时我在 feature_666 分支,非常聚精会神加持高专注地实现一个功能 666 模块，简直键盘如飞的编写代码～～～ 然后这时，客户反馈出一个 bug , 非常严重，必须立马解决，优先级为 0 ！！！ 于是，我需要去到 release 分支去 checkout 新的分支去工作了，但是 666 功能还没完成怎么办？ 此时我面临着一个选择题： A：提交后切换，代码保存到分支 feature_666，却产生一个无意义的提交 B：不提交直接切换，然而这个选项根本没人会选。\n是不是很难选，此时，别忘记还有 C 选项！\nC：使用 git stash , 将当前修改(未提交的代码)存入缓存区，切换分支修改 bug ,回来再通过 git stash pop 取出来。 ———————————————— 版权声明：本文为CSDN博主「DRPrincess」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/qq_32452623/article/details/76100140\n 命令:\ngit stash #将修改储存到暂存区,工作区会删除修改\rgit stash show #查看刚才暂存的修改\rgit stash pop #取出修改并删除记录列表中对应记录\rgit stash list #查看暂存区的所有暂存修改记录\rgit stash save \u0026lt;message\u0026gt; #给stash 存储的修改起个名字并保存\rgit stash apply stash@{X} #取出相应的暂存\rgit stash drop stash@{X} #将记录列表中取出的对应暂存记录删除\r标签 命令:\ngit tag \u0026lt;tag name\u0026gt; #打一个标签\rgit checkout \u0026lt;tag name\u0026gt; #检出一个标签\rgit tag -d \u0026lt;tag name\u0026gt; #删除一个标签\r远程交互 添加远程仓库(git init方式)  初始化  git init\r 添加远程仓库  git remote add \u0026lt;repository name\u0026gt; \u0026lt;url\u0026gt; \ngit remote add origin xxx.git\r 拉取代码  git fetch\r 将当前分支关联远程分支  git branch -u origin/master\r 关联关系  git merge origin/master --allwo-unrelated-histories\r 合并当前与远程分支  git merge origin/dev\r克隆方式(git clone)  克隆仓库  git clone url\r 检出分支  git checkout -b \u0026lt;local branch name\u0026gt; \u0026lt;remote branch name\u0026gt; #拉取本地分支与远程分支关联\r有关远程分支的命令 git branch -a #查看远程分支\rgit branch -vv #查看本地分支与远程分支的关联\r本地分支与远程分支名称问题 本地分支与远程对应的分支尽量同名,如果不同命会出现问题:\nfatal: The upstream branch of your current branch does not match\rthe name of your current branch. To push to the upstream branch\ron the remote, use\rgit push origin HEAD:dev\rTo push to the branch of the same name on the remote, use\rgit push origin HEAD\rTo choose either option permanently, see push.default in \u0026#39;git help config\u0026#39;.\r可以使用命令提交:\ngit push origin dev2:dev\r或者更改git 配置:\ngit config --global push.default upstream\r操纵远程分支  将本地分支推送到远程  git checkout -b feature-branch #创建并切换到分支feature-branch git push origin feature-branch:feature-branch #推送本地的feature-branch(冒号前面的)分支到远程origin的feature-branch(冒号后面的)分支(没有会自动创建)\r 删除远程分支  git push origin --delete \u0026lt;branch name\u0026gt; # 或者\rgit branch -r -d origin/\u0026lt;branch name\u0026gt;\rgit push origin :\u0026lt;branch name\u0026gt;\r","id":0,"section":"posts","summary":"基本概念 四度空间: 工作区:Workspace 就是你在电脑里能看到的目录 暂存区: Index/Stage/Cached 英文叫stage, 或index。一般存放在 \u0026ldquo;.g","tags":["Git"],"title":"Git不完全使用指南","uri":"https://fhxisdog.github.io/2020/03/git%E4%B8%8D%E5%AE%8C%E5%85%A8%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","year":"2020"},{"content":"","id":1,"section":"posts","summary":"","tags":null,"title":"Posts","uri":"https://fhxisdog.github.io/posts/","year":"2020"},{"content":"什么是Restful? REST这个词，是Roy Thomas Fielding在他2000年的博士论文中提出的。\nFielding是一个非常重要的人，他是HTTP协议（1.0版和1.1版）的主要设计者、Apache服务器软件的作者之一、Apache基金会的第一任主席。所以，他的这篇论文一经发表，就引起了关注，并且立即对互联网开发产生了深远的影响。\n他这样介绍论文的写作目的：\n \u0026ldquo;本文研究计算机科学两大前沿\u0026mdash;-软件和网络\u0026mdash;-的交叉点。长期以来，软件研究主要关注软件设计的分类、设计方法的演化，很少客观地评估不同的设计选择对系统行为的影响。而相反地，网络研究主要关注系统之间通信行为的细节、如何改进特定通信机制的表现，常常忽视了一个事实，那就是改变应用程序的互动风格比改变互动协议，对整体表现有更大的影响。我这篇文章的写作目的，就是想在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。\u0026rdquo;\n(This dissertation explores a junction on the frontiers of two research disciplines in computer science: software and networking. Software research has long been concerned with the categorization of software designs and the development of design methodologies, but has rarely been able to objectively evaluate the impact of various design choices on system behavior. Networking research, in contrast, is focused on the details of generic communication behavior between systems and improving the performance of particular communication techniques, often ignoring the fact that changing the interaction style of an application can have more impact on performance than the communication protocols used for that interaction. My work is motivated by the desire to understand and evaluate the architectural design of network-based application software through principled use of architectural constraints, thereby obtaining the functional, performance, and social properties desired of an architecture. )\n Fielding将他对互联网软件的架构原则，定名为REST，即Representational State Transfer的缩写。(\u0026ldquo;表现层状态转化\u0026rdquo;)。\n如果一个架构符合REST原则，就称它为RESTful架构。\n要理解RESTful架构，最好的方法就是去理解Representational State Transfer这个词组到底是什么意思，它的每一个词代表了什么涵义。 如果你把这个名称搞懂了，也就不难体会REST是一种什么样的设计。\n总的来说,Restful架构就是：\n　（1）每一个URI代表一种资源；\n　（2）客户端和服务器之间，传递这种资源的某种表现层；\n　（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现\u0026quot;表现层状态转化\u0026rdquo;。\n什么是Rsocket?  RSocket is a binary protocol for use on byte stream transports such as TCP, WebSockets, and Aeron.\n\u0026ldquo;RSocket是一种二进制协议，用于TCP、websocket和Aeron等字节流传输。\u0026rdquo;\nIt enables the following symmetric interaction models via async message passing over a single connection:\n\u0026ldquo;它支持以下对称交互模型通过异步消息传递一个单一的连接:\u0026rdquo;\n request/response (stream of 1) request/stream (finite stream of many) fire-and-forget (no response) channel (bi-directional streams)  It supports session resumption, to allow resuming long-lived streams across different transport connections. This is particularly useful for mobile⬄server communication when network connections drop, switch, and reconnect frequently.\n\u0026ldquo;它支持会话恢复，允许在不同的传输连接之间恢复长生命周期的流。当网络连接频繁地断开、切换和重新连接时，这对于移动服务器通信尤其有用。\u0026rdquo;\n    模式 说明     请求-响应（request/response） 这是最典型也最常见的模式。发送方在发送消息给接收方之后，等待与之对应的响应消息。   请求-响应流（request/stream） 发送方的每个请求消息，都对应于接收方的一个消息流作为响应。   发后不管（fire-and-forget） forget） 发送方的请求消息没有与之对应的响应。   通道模式（channel） 在发送方和接收方之间建立一个双向传输的通道。    什么是gRpc？ gRPC是一个高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。\ngRPC提供了一种简单的方法来精确地定义服务和为iOS、Android和后台支持服务自动生成可靠性很强的客户端功能库。\n客户端充分利用高级流和链接功能，从而有助于节省带宽、降低的TCP链接次数、节省CPU使用、和电池寿命。\ngRPC具有以下重要特征：\n强大的IDL特性 RPC使用ProtoBuf来定义服务，ProtoBuf是由Google开发的一种数据序列化协议，性能出众，得到了广泛的应用。\n支持多种语言 支持C++、Java、Go、Python、Ruby、C#、Node.js、Android Java、Objective-C、PHP等编程语言。 3.基于HTTP/2标准设计\n谷歌机翻时间  Representational State Transfer (REST) has become the de facto standard for communicating between microservices. That is not a good thing — in fact, it’s a very bad thing. How did this come to pass? Well, at the time REST emerged, there were even worse options. When Roy Fielding proposed REST in 2000, REST was a kale sandwich in a field of much worse tasting sandwiches.\n\u0026ldquo;代表性状态转移（REST）已成为微服务之间进行通信的事实上的标准。 那不是一件好事-实际上，这是一件非常不好的事。 这是怎么发生的？ 好吧，在REST出现时，还有更糟糕的选择。 当Roy Fielding于2000年提出REST时，REST是羽衣甘蓝三明治，在口味更差的三明治领域。\u0026rdquo;\nPeople were using SOAP, RMI, CORBA, and EJBs. JSON was a welcome respite from XML. It was easy to use URLs to spit out some text. Plus, JavaScript started to really take off in browsers and it was much easier to deal with REST, than it was SOAP. Unlike the recent microservice trend, most applications were the traditional monolithic 3-tier application. The source of most of the external traffic they were talking with was a browser, so when they had to produce something REST was an easy choice. Many people began to move from bigger commercial offerings like WebSphere to Jetty and Tomcat. These didn’t even have the facilities to deal with EJBs, so REST was a convenient choice.\n\u0026ldquo;人们使用SOAP、RMI、CORBA和ejb。JSON是XML的一个很好的缓冲。使用url输出一些文本是很容易的。另外，JavaScript开始在浏览器中流行起来，它比SOAP更容易处理REST。与最近的微服务趋势不同，大多数应用程序是传统的单片3层应用程序。他们所谈论的大多数外部流量的来源是一个浏览器，所以当他们不得不产生一些东西时，REST是一个简单的选择。许多人开始从WebSphere这样的大型商业产品转向Jetty和Tomcat。它们甚至没有处理ejb的设施，因此REST是一个方便的选择。\u0026rdquo;\nWhat does this have to do with microservices? Early microservice pioneers moved to microservices for a different reason than people are doing it today. They moved to them because they had to deal with massive scale. They started to get so many users that they couldn’t serve everything in a single monolith. And unlike many enterprises today, cost wasn’t the motivating factor — time was. They needed to get their services out yesterday. As they got more and more users their monolith wasn’t cutting it, so they cut their app up into smaller pieces. They could deploy these applications on thousands of servers, and then eventually virtual machines.\n\u0026ldquo;这与微服务有什么关系？ 早期的微服务先驱之所以转向微服务，其原因不同于今天的人们。 他们之所以搬到他们这里，是因为他们不得不面对大规模的交易。 他们开始吸引大量用户，以至于无法在一个整体中提供所有服务。 而且与今天的许多企业不同，成本不是动力，而是时间。 他们需要昨天取消服务。 随着他们越来越多的用户，他们的独裁者并没有削减它，因此他们将他们的应用程序分成了较小的部分。 他们可以将这些应用程序部署在数千台服务器上，然后再部署在虚拟机上。\u0026rdquo;\nFurthermore, they could deploy their applications very quickly. Companies that adopted this model were able to survive. During this race though, there wasn’t much time to consider what they were doing. These early pioneers had to deal with exponential user growth and competition, so it makes sense they would opt for tactical solutions. One of these was using REST to communicate between services.\n\u0026ldquo;此外，他们可以非常快速地部署应用程序。 采用这种模式的公司能够生存。 不过在这场比赛中，没有太多时间去考虑他们在做什么。 这些早期的开拓者必须应对指数级的用户增长和竞争，因此他们选择战术解决方案是有道理的。 其中之一是使用REST在服务之间进行通信。\u0026rdquo;\n Why REST is bad for Microservices  When programming an application, your programing language eventually ends up as machine code. This is obvious. Even an “interpreted” language like Java or JavaScript does, as well. Instead of compiling directly to machine code, they use a JIT or just-in-time compiler. In some cases, JIT’ed code can be faster than what an engineer can write and tune by hand — VMs are truly a miracle of modern computer science.\n\u0026ldquo;在编写应用程序时，您的编程语言最终会变成机器码。这是显而易见的。甚至像Java或JavaScript这样的“解释型”语言也可以。他们使用JIT或即时编译器，而不是直接编译成机器码。在某些情况下，JIT代码的速度比工程师手工编写和调优的速度还要快——vm确实是现代计算机科学的一个奇迹。\u0026rdquo;\nWhy then do we waste this miracle? Instead of sending binary messages optimized for machines, on a protocol optimized for services, we send messages optimized for humans. We send around things like JSON and XML using a protocol that was designed for sending books. Think how ridiculous this is! You have a program that is binary, that turns a binary structure to text, sends it over the network in text, to a machine that parses and turns it back into binary structure to be processed in an application.\n\u0026ldquo;那为什么我们要浪费这个奇迹呢？ 我们不是根据针对服务优化的协议发送针对机器优化的二进制消息，而是发送针对人员优化的消息。 我们使用旨在发送书籍的协议来发送JSON和XML之类的东西。 认为这是多么荒谬！ 您有一个二进制程序，该程序将二进制结构转换为文本，然后通过网络将其以文本形式发送到计算机，该计算机将其解析并转换回二进制结构，以在应用程序中进行处理。\u0026rdquo;\nAvoiding cache misses on a modern CPU is critical. Unfortunately, parsing tons of JSON and Strings is going to cause cache misses!\n\u0026ldquo;避免现代CPU上的高速缓存未命中至关重要。 不幸的是，解析大量的JSON和Strings将导致缓存未命中！\u0026rdquo;\nAn often-cited reason to use REST is that it’s easy to debug because its “human readable”. Not being easy to read is a tooling issue. JSON text is only human readable because there are tools that allow you to read it – otherwise it’s just bytes on a wire. Furthermore, half the time the data being sent around is either compressed or encrypted — both of which aren’t human readable. Besides, how much of this can a person “debug” by reading? If you have a service that averages a tiny 10 requests per second with a 1 kilobyte JSON that is the equivalent to 860 megabytes of data a day, or 250 copies of War and Peace every day. There is no one who can read that, so you’re just wasting money.\n经常使用REST的原因是它易于调试，因为它的“可读性”。 不容易阅读是一个工具问题。 JSON文本只有人类可以阅读，因为有一些工具可让您读取JSON文本；否则，它只是线路上的字节。 此外，一半左右的数据被压缩或加密-两者都不是人类可读的。 此外，一个人可以通过阅读“调试”多少？ 如果您有一项服务，平均每秒钟平均有10个请求，并带有1 KB的JSON，则相当于每天860兆字节的数据，或每天250份《战争与和平》。 没有人可以阅读，所以您只是在浪费金钱.\nThen, there is the case where you need to send binary data around, or you want to use a binary format instead of JSON. To do that, you must Base64 encode the data. This means that you essentially serialize the data twice — again, not an efficient way to use modern hardware.\n然后，在某些情况下，您需要发送二进制数据，或者您想要使用二进制格式而不是JSON。 为此，您必须对数据进行Base64编码。 这意味着您实际上要对数据进行两次序列化，这又不是使用现代硬件的有效方法。\nAt the end of the day, REST was implemented as a hack on top of HTTP. And HTTP is being used as a hack to send transport data between services. HTTP was designed to schlep books around the Internet. It shouldn’t be used for services to communicate with one other. Instead, use a format that is optimized for your application — the thing that is processing all the data.\n归根结底，REST被实现为基于HTTP的黑客。 HTTP被用作在服务之间发送传输数据的黑客。 HTTP的设计目的是使Internet上的书籍不被窃取。 不应将其用于服务之间的通信。 相反，请使用针对您的应用程序优化的格式-处理所有数据的事物。\n What is good Microservice Communication?  If we suppose for a moment that REST isn’t the best choice for service to service communication, then what is? Let’s look at some of the things we would want in a protocol designed for microservice communication.\n如果我们假设REST不是服务到服务通信的最佳选择，那么什么才是呢?让我们来看看为微服务通信设计的协议中需要的一些东西。\nFor starters, we want things to be bi-directional. That’s a huge problem with REST — clients can only call servers. When both sides have equal ability to call each other, you can create interactions between applications in a natural manner. Otherwise you are forced to devise clunky workarounds such as long-polling to simulate server-initiated calls. You can partially get around it with HTTP/2, but the call still needs to be initiated by the client. What you want is the ability for clients and servers to be free to call each other as necessary.\n首先，我们希望事情是双向的。这是REST的一个大问题——客户端只能调用服务器。当双方具有同等的调用能力时，您可以以自然的方式在应用程序之间创建交互。否则，您将被迫设计笨拙的工作区，例如长轮询，以模拟服务器发起的调用。您可以使用HTTP/2部分地绕过它，但是调用仍然需要由客户机发起。您想要的是客户机和服务器能够在必要时自由地相互调用。\nAnother requirement is the connection between services must support multiple requests on same connection – at the same time. This is called multiplexing. Now, with a single connection, there needs to be some way to distinguish one request from another. This is unlike HTTP where one request starts when another one ends. With multiplexing, you are going to need keep track of the different requests. A good way to do this is having each request represented with a binary frame. Each frame can hold the request, as well as metadata about the request. Then, it can be used to get the frame to the correct location.\n另一个要求是服务之间的连接必须同时支持同一连接上的多个请求。这叫做多路复用。现在，对于单个连接，需要有一些方法来区分不同的请求。这与HTTP不同，一个请求在另一个请求结束时开始。使用多路复用，您将需要跟踪不同的请求。实现此目的的一种好方法是用二进制帧表示每个请求。每个帧可以保存请求，以及关于请求的元数据。然后，它可以用来获得帧的正确位置。\nWhen sending data over a single connection, you need the ability to fragment requests. A large request with a single connection will block all the other requests behind it, aka head-of-the-line blocking. What is needed, instead, is to fragment the requests into smaller sizes and send those over the network. Since data being sent is framed, it can be broken into smaller frame fragments, and then reassembled on the other side. This way, requests can interleave with each other. No longer can a large request block a smaller request. This will create a much more responsive system.\n当通过单个连接发送数据时，您需要能够分段请求。带有单个连接的大请求将阻塞它后面的所有其他请求，也称为前端阻塞。相反，需要的是将请求分割成更小的大小并通过网络发送。由于发送的数据是有框架的，所以可以将其分解成更小的框架片段，然后在另一端重新组装。这样，请求就可以相互交错。一个大的请求不再能阻塞一个小的请求。这将创建一个响应性更强的系统。\nAlso, the ability to exchange metadata about a connection is useful. Sometimes there is data to send that isn’t necessarily part of a business transaction — things like configuring the overall tracing level or exchanging information for dictionary-based compression. These are things that don’t have to do with business logic but could be controlled at a connection level. The ability to exchange metadata would provide for that.\n另外，交换关于连接的元数据的能力也很有用。有时需要发送的数据不一定是业务事务的一部分—比如配置整个跟踪级别或为基于字典的压缩交换信息。这些事情与业务逻辑无关，但是可以在连接级别进行控制。交换元数据的能力将为此提供支持。\nOften in application code, a function or method will be called that takes a list, returns a list, or both. This happens in microservices all the time, as well. REST doesn’t deal with these situations well and this leads to all sorts of hacks and complexity.\n通常在应用程序代码中，一个函数或方法将被调用，它接受一个列表，返回一个列表，或者两者兼而有之。这在微服务中也经常发生。REST不能很好地处理这些情况，这导致了各种各样的技巧和复杂性。\nWhat’s needed is a protocol that can deal with iterative data easily and naturally — like you do in your application. It doesn’t make sense to read an entire list of data, process it and then return a list of data once everything is processed. What you want is the ability to process data as it comes. You want to be able to stream data. If there is a long list of data, you don’t want to wait for that data to be processed — you want to send the data off as it becomes available and get the responses back as they occur.\n我们需要的是一种协议，它可以轻松而自然地处理迭代数据—就像您在应用程序中所做的那样。读取整个数据列表、处理它并在处理完所有内容后返回数据列表是没有意义的。你想要的是处理数据的能力。您希望能够流数据。如果有一个很长的数据列表，您不希望等待处理数据—您希望在数据可用时发送数据，并在响应出现时将其返回。\nThis will create a much more responsive system. It can be used for all sorts of things from reading bytes from a file and streaming it over the network, to returning results from a database query, to feeding browser click-stream data to a back-end. If first-class streaming support is present in the protocol, it’s not necessary to include another system like Spark to do stream processing. Nor is it necessary to include something like Kafka unless you want to store data.\n这将创建一个响应性更强的系统。它可以用于各种各样的事情，从从文件读取字节并通过网络传输，到从数据库查询返回结果，再到将浏览器点击流数据提供给后端。如果协议中提供了一流的流支持，则不需要包含其他系统(如Spark)来进行流处理。除非您想存储数据，否则也没有必要包含诸如Kafka之类的东西。\nFor data that is sent via streams, the next thing needed is application flow control. Byte-level flow control works for something like TCP because everything is the same size, and generally, the same cost to process from the perspective of the network card. However, in an application, not everything is the same cost. There could be a message that is 10 kilobytes that takes 10 milliseconds to process, but another message that is 10 bytes that takes 10 seconds.\n对于通过流发送的数据，接下来需要的是应用程序流控制。字节级流控制适用于TCP之类的东西，因为所有东西的大小都是相同的，而且从网卡的角度来看，处理的成本通常是相同的。然而，在应用程序中，并不是所有东西的成本都是相同的。可能有一条消息是10千字节，需要10毫秒来处理，但是另一条消息是10字节，需要10秒。\nAnother scenario found in microservices is that downstream services process data at slower rates than the data can be processed. This means that TCP buffers are never full. There needs to be some way to control the flow of traffic to keep from overwhelming downstream services in order to keep them responsive.\n微服务中的另一个场景是，下游服务处理数据的速度比处理数据的速度慢。这意味着TCP缓冲区永远不会满。需要有某种方式来控制流量，以避免下游服务无法承受，从而保持它们的响应能力。\nThe application must be able to control the rate that messages can flow independent of the underlying network bytes. For an application developer it is difficult to reason how many bytes a message is especially between languages. On the other hand, it is simple for a developer to reason about how many messages they are sending. This way, the service can arbitrage between the network flow control and the application flow control. Sometimes an application can process data faster than the network, and other times, the network can process data faster than the application. Having application flow control will ensure that tail latency is stable as well — again creating a responsive application. It also prevents the need for unbounded queues, a dangerous hack that is found in other applications.\n应用程序必须能够控制消息可以独立于底层网络字节流动的速率。对于应用程序开发人员来说，很难推断消息的字节数，尤其是在不同语言之间。另一方面，对于开发人员来说，推断他们发送了多少消息是很简单的。通过这种方式，服务可以在网络流控制和应用程序流控制之间进行仲裁。有时应用程序处理数据的速度比网络快，有时网络处理数据的速度比应用程序快。应用程序流控制将确保尾延迟也是稳定的—再次创建响应型应用程序。它还防止了对无界队列的需要，这是在其他应用程序中发现的一种危险的攻击。\nAs mentioned above, a huge drawback of RESTful web services is that they are (de facto) implemented as text-based. To send any binary data requires you Base64 encode the data —and serialize everything twice. What you really want is something that is binary — because it can represent anything — including text. Also, it is significantly more efficient for your application to process binary data than text, especially numbers. Additionally, they are naturally more compact — they don’t have extra braces, curly brackets, or angle brackets in them. Finally, if your data is binary, there is a possibility too for zero copy serialization and deserialization, depending on the format. This is a little out of the scope of this article, but check things out like Simple Binary Encoding (SBE), and Flatbuffers. They are significantly faster than using JSON.\n如上所述，rest式web服务的一个巨大缺点是它们(实际上)是作为基于文本的实现的。要发送任何二进制数据，需要使用Base64对数据进行编码，并对所有内容进行两次序列化。你真正想要的是二进制的东西——因为它可以表示任何东西——包括文本。而且，应用程序处理二进制数据的效率要比处理文本(尤其是数字)高得多。此外，它们自然更紧凑——它们没有额外的大括号、花括号或尖括号。最后，如果您的数据是二进制的，也有可能进行零拷贝序列化和反序列化，这取决于格式。这有点超出了本文的范围，但是可以查看简单二进制编码(SBE)和Flatbuffers。它们比使用JSON要快得多。\nFinally, you want to be able to send your requests over different transports. RESTful web services typically use HTTP, which uses only TCP. What you really want is a way to abstract the networking away, so that you only program to a specification and don’t have to worry about the transport. At the same time, if it’s talking to browsers your application should be able to run over WebSocket. You should not have to switch to a new networking toolkit every time you want to change where your application is deployed, it should be easy to swap out transports without any applications changes.\n最后，您希望能够通过不同的传输传输请求。RESTful web服务通常使用HTTP，而HTTP只使用TCP。您真正想要的是一种抽象网络的方法，这样您就可以只根据规范进行编程，而不必担心传输。同时，如果它与浏览器对话，你的应用程序应该能够在WebSocket上运行。您不应该每次想要更改应用程序的部署位置时都必须切换到新的网络工具包，应该很容易在不更改任何应用程序的情况下交换传输。\n Which Protocol Fits the Bill? Some would suggest that REST and HTTP/2 are a better fit. HTTP/2 is better than HTTP/1 but if you read the specs, its sole purpose is to create a better web browser protocol. It was never designed or intended for use in microservices. And that is what it should be used for — server HTML to web browsers. Again, it was never intended for microservices communication. Furthermore, you still must deal with URLs and matching the different HTTP methods to your application — these methods were never really intended for server to server communication.\n有些人认为REST和HTTP/2是更好的选择。HTTP/2比HTTP/1更好，但如果您阅读规范，它的唯一目的是创建更好的web浏览器协议。它从未被设计或打算用于微服务。这是它应该用于服务器HTML到web浏览器。同样，它也从未打算用于微服务通信。此外，您还必须处理url并将不同的HTTP方法与您的应用程序相匹配——这些方法从未真正用于服务器之间的通信。\nHTTP/2 does provide streaming, but it only provides it for server push. So, using REST over HTTP/2 requires initiating a request on a client and then pushing the data to the server. HTTP/2 flow control is byte-based flow control. This is good for a web browser, but not good for an application. There is still no way to control the flow of an application by the way that work is being done on an application.\nHTTP/2确实提供了流，但它只提供了服务器推送。因此，在HTTP/2上使用REST需要在客户机上启动一个请求，然后将数据推送到服务器。HTTP/2流控制是基于字节的流控制。这对于web浏览器很好，但是对于应用程序就不好了。仍然无法通过对应用程序执行工作的方式来控制应用程序流。\nThere has been a lot of noise lately about using gRPC. gRPC is very similar in concept to SOAP. Instead of using XML to define services, it uses Protobuf. Like SOAP, it’s a hodge-podge of URL and Header magic — this time using HTTP/2. This means gRPC is explicitly tied to HTTP/2, a protocol designed for web browsers. And what is worse, it isn’t supported in a web browser.\n最近有很多关于使用gRPC的噪音。gRPC在概念上与SOAP非常相似。它使用Protobuf而不是XML来定义服务。像SOAP一样，它是URL和报头魔力的大杂烩——这次使用的是HTTP/2。这意味着gRPC被明确地绑定到HTTP/2，一个为web浏览器设计的协议。更糟糕的是，它在web浏览器中不受支持。\nInstead you must use a proxy to turn your gRPC calls in to REST calls, thus defeating the purpose for using it. This highlights how poorly designed gRPC is. Why would you use HTTP/2 for a protocol and not make sure it works in a browser? You are forever limited by its original purpose, yet not able to use it where it was intended. This leads to my next point: the biggest limitation of REST is the fact it’s tied to HTTP.\n相反，您必须使用代理将gRPC调用转换为REST调用，从而破坏了使用它的目的。这凸显了gRPC的设计有多么糟糕。为什么使用HTTP/2作为协议，却不能确保它在浏览器中工作?你永远被它最初的用途所限制，却不能在它原本的地方使用它。这就引出了我的下一个观点:REST最大的限制是它与HTTP绑定。\nWhat you want is a protocol that is designed for service-to-service communication. Using a protocol that is specifically-designed for services to talk to each other will create significantly simpler and more reliable applications. There will not be any hacks, workarounds, or impedance mismatches.\n您需要的是为服务到服务通信设计的协议。使用专门为服务相互通信而设计的协议将创建更简单、更可靠的应用程序。不会有任何黑客，工作区，或阻抗不匹配。\nConstruction materials are a good analogy. Wood is great for building small bridges. You can use it to span a small stream or creek and it isn’t a problem.\n建筑材料是一个很好的类比。木材是建造小桥的好材料。你可以用它来跨越一条小溪，这不是问题。\nWhen engineers started using it to span wider distances things got complicated.\n当工程师们开始用它来跨越更宽的距离时，事情变得复杂起来\nWood bridges like this worked. But, they had a very high failure rate compared to modern bridges made of better materials. They were also very complicated and took much, much longer to build. This why we now use steel and concrete. They are easier to maintain, cheaper to build, last longer, and can span far greater distances.\n这样的木桥很管用。但是，与用更好的材料建造的现代桥梁相比，它们的失败率非常高。它们也很复杂，需要花很长时间来建造。这就是为什么我们现在使用钢铁和混凝土。它们更容易维护，建造成本更低，寿命更长，可以跨越更远的距离。\nWe need a modern material to replace HTTP for creating modern services. Open source RSocket is designed for services. It is a connection-oriented, message-driven protocol with built-in flow control at the application level. It works in a browser equally as well as on a server. In fact, a web browser can serve traffic to backend microservices. It is also binary. It works equally well with text and binary data, and the payloads can be fragmented. It models all the interactions that you do in your application as network primitives. This means you can stream data or do Pub/Sub without having to setup an application queue.\n我们需要一种现代材料来代替HTTP来创建现代服务。开源RSocket是为服务而设计的。它是一个面向连接的消息驱动协议，在应用程序级别具有内置的流控制。它在浏览器和服务器上都能工作。实际上，web浏览器可以为后端微服务提供流量。它也是二进制的。它同样适用于文本和二进制数据，并且有效负载可以被分割。它将应用程序中进行的所有交互建模为网络原语。这意味着您可以流数据或做发布/订阅，而不必设置应用程序队列。\nREST is a decent solution where it makes sense. One place it doesn’t make sense is microservices. Distributed systems are difficult enough on their own. The last thing that we need is to make them more complex by using something not designed for them.\n在有意义的地方，休息是一个不错的解决方案。微服务是一个没有意义的地方。分布式系统本身就够难的了。我们需要做的最后一件事就是使用一些不是为它们设计的东西来让它们变得更复杂。\n参考链接 理解RESTful架构\n使用 RSocket 进行反应式数据传输\nRsocket.io\ngRPC的那些事 - streaming\nGive REST a Rest with RSocket \n","id":2,"section":"posts","summary":"什么是Restful? REST这个词，是Roy Thomas Fielding在他2000年的博士论文中提出的。 Fielding是一个非常重要的人，他是H","tags":["java","spring boot","smicroservices"],"title":"Restful、gRpc、Rsocket","uri":"https://fhxisdog.github.io/2019/11/restfulgrpcrsocket/","year":"2019"},{"content":"问题描述 如果项目是多模块，如果只想打包某一模块，会出现找不到依赖的错误提示。\n项目结构如下:\nA: ----B ----C ----D 如果想只打包C模块，可以执行以下命令:\nmvn -pl -am C package -DskipTests -Ptest\n多模块工程的打包命令参考：\n-am --also-make 同时构建所列模块的依赖模块； -amd -also-make-dependents 同时构建依赖于所列模块的模块； -pl --projects \u0026lt;arg\u0026gt; 构建制定的模块，模块间用逗号分隔； -rf -resume-from \u0026lt;arg\u0026gt; 从指定的模块恢复反应堆。 看英文的更助于理解：\n-am,--also-make If project list is specified, also build projects required by the list -amd,--also-make-dependents If project list is specified, also build projects that depend on projects on the list -pl,--projects \u0026lt;arg\u0026gt; Comma-delimited list of specified reactor projects to build instead of all projects. A project can be specified by [groupId]:artifactId or by its relative path. -rf,--resume-from \u0026lt;arg\u0026gt; Resume reactor from specified project 参考:  https://my.oschina.net/ccor/blog/704365\n @\n","id":3,"section":"posts","summary":"问题描述 如果项目是多模块，如果只想打包某一模块，会出现找不到依赖的错误提示。 项目结构如下: A: ----B ----C ----D 如果想只打包C模块，可以执行以下命令: mvn -pl","tags":["maven","java","spring boot"],"title":"多模块Maven工程单独打包某一模块工程","uri":"https://fhxisdog.github.io/2019/11/%E5%A4%9A%E6%A8%A1%E5%9D%97maven%E5%B7%A5%E7%A8%8B%E5%8D%95%E7%8B%AC%E6%89%93%E5%8C%85%E6%9F%90%E4%B8%80%E6%A8%A1%E5%9D%97%E5%B7%A5%E7%A8%8B/","year":"2019"},{"content":"\u0026gt; Configure project :core Checking the license for package Android SDK Platform 28 in /opt/android/sdk/licenses Warning: License for package Android SDK Platform 28 not accepted. FAILURE: Build failed with an exception. * What went wrong: A problem occurred configuring project ':core'. \u0026gt; Failed to install the following Android SDK packages as some licences have not been accepted. platforms;android-28 Android SDK Platform 28 To build this project, accept the SDK license agreements and install the missing components using the Android Studio SDK Manager. Alternatively, to transfer the license agreements from one workstation to another, see http://d.android.com/r/studio-ui/export-licenses.html Using Android SDK: /opt/android/sdk * Try: Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org BUILD FAILED in 28s Exited with code 1 解决方法:\n进入 $Andorid_HOME/tools/bin,执行yes | ./sdkmanager --licenses\n","id":4,"section":"posts","summary":"\u0026gt; Configure project :core Checking the license for package Android SDK Platform 28 in /opt/android/sdk/licenses Warning: License for package Android SDK Platform 28 not accepted. FAILURE: Build failed with an exception. * What went wrong: A problem occurred configuring project ':core'. \u0026gt; Failed to install the following Android SDK packages as some licences have not been accepted. platforms;android-28 Android SDK Platform 28 To build this project, accept the SDK license","tags":["flutter","android"],"title":"Android Platform 28 SDK License Not Accepted","uri":"https://fhxisdog.github.io/2019/11/android-platform-28-sdk-license-not-accepted/","year":"2019"},{"content":"安装python必须的依赖 sudo pip install jedi elpy rope pylint\nemacs配置 在～/.emacs.d/路径新建文件init.el\n添加以下配置:\n(require 'package) (package-initialize) ;;配置包管理列表的源 (setq package-archives '((\u0026quot;gnu\u0026quot; . \u0026quot;http://elpa.emacs-china.org/gnu/\u0026quot;) (\u0026quot;melpa\u0026quot; . \u0026quot;https://stable.melpa.org/packages/\u0026quot;))) (require 'cl) (defvar my/packages '( company better-deafults material-theme elpy company-jedi switch-window projectile neotree ) ) ;;jedi配置 (setq jedi:setup-keys t) (setq jedi:complete-on-dot t) (setq elpy-rpc-backend \u0026quot;jedi\u0026quot;) (when (fboundp 'jedi:setup) (jedi:setup)) ;; 自动补全 (global-company-mode t) (add-hook 'after-init-hook 'global-company-mode) ;; 使用material主题 (load-theme 'material t) ;; enable python插件 (elpy-enable) ;;设置切换窗口为a-z (setq switch-window-shortcut-style 'qwerty) (global-set-key (kbd \u0026quot;C-x o\u0026quot;) 'switch-window) ;;projectilep配置 (projectile-mode +1) (define-key projectile-mode-map (kbd \u0026quot;C-c p\u0026quot;) 'projectile-command-map) ;;neotree配置 (setq neo-smart-open t) (setq projectile-switch-project-action 'neotree-projectile-action) (defun neotree-project-dir () \u0026quot;Open NeoTree using the git root.\u0026quot; (interactive) (let ((project-dir (projectile-project-root)) (file-name (buffer-file-name))) (neotree-toggle) (if project-dir (if (neo-global--window-exists-p) (progn (neotree-dir project-dir) (neotree-find file-name))) (message \u0026quot;Could not find git project root.\u0026quot;)))) emacs配置 进入Emacs,ALT-X输入list-packages\n安装必须的包:\n\tcompany better-deafults material-theme elpy company-jedi switch-window projectile neotree 解释:\n company ;;自动补全 better-deafults material-theme ;;material主题 elpy ;;python开发必须环境 company-jedi ::jedi switch-window ::快速切换窗口 projectile ;;项目管理 neotree ;;树形文件结构 ","id":5,"section":"posts","summary":"安装python必须的依赖 sudo pip install jedi elpy rope pylint emacs配置 在～/.emacs.d/路径新建文件init.el 添加以下配置: (require 'package) (package-initialize) ;;配置包管理列","tags":["linux","emacs"],"title":"Emacs搭建python开发环境","uri":"https://fhxisdog.github.io/2019/11/emacs%E6%90%AD%E5%BB%BApython%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","year":"2019"},{"content":"含义 C -\u0026gt; CTRL\nM -\u0026gt; ALT\nS-\u0026gt;SHIFT\n基本命令    快捷键 含义 快捷键 含义     C-x C-f 打开文件 C-x C-c 关闭emacs   C-x C-s 保存文件 C-x C-w 当前缓冲区另存为   C-g 取消命令 C-x C-b 打开当前缓冲区列表   C-x b 打开一个缓冲区 C-x K 关闭当前缓冲区   C-x C-v 关闭当前缓冲区并打开新的文件      移动命令    快捷键 含义 快捷键 含义     C-n 向下移动一行 C-p 向上移动一行   C-f 向前移动一个字符 C-b 向后移动一个字符   C-a 移动到行首 C-e 移动到行尾   M-b 向后移动一个单词 M-f 向前移动一个单词   M-v 向上移动半屏 C-v 向下移动半屏   M-\u0026gt; 到文件末尾 M-\u0026lt; 到文件开头   M-g M-g 跳到xx行      窗口命令    快捷键 含义 快捷键 含义     C-x 2 水平分割窗口 C-x 3 垂直分割窗口   C-x 0 关闭当前窗口 C-x 1 关闭其他窗口   C-x 4 f 新tab打开文件 C-x 5 f 新窗口打开文件   C-x o 切换窗口 C-x 5 2 新建窗口   C-M-V 向下滚动其他窗口 C-M-S-V 向上滚动其他窗口    编辑命令    快捷键 含义 快捷键 含义     C-space 开始设置标记 C-@ 开始设置标记   M-w 复制标记内容 C-w 剪切选中内容   M-d 删除后面一个单词 C-d 删除后面一个字符   C-y 粘贴 C-k 删除一行   M-u 后面一个单词变成大写 M-l 后一个单词变成小写   M-c 后面一个单词首字母大写      替换命令    快捷键 含义 快捷键 含义     C-s 向下搜索 C-r 向上搜索   M-% 替换      文件夹命令    快捷键 含义 快捷键 含义     C-s d 打开文件夹列表 n 向下移动   p 向上移动 v 编辑光标所在文件   d 标记为删除 D 马上删除   x 执行标记 C 拷贝当前文件   R 重命名 + 新建文件夹   z 压缩文件 ！ 对光标所在文件执行shell命令   q 退出      ","id":6,"section":"posts","summary":"含义 C -\u0026gt; CTRL M -\u0026gt; ALT S-\u0026gt;SHIFT 基本命令 快捷键 含义 快捷键 含义 C-x C-f 打开文件 C-x C-c 关闭emacs C-x C-s 保存文件 C-x C-w 当前缓冲区另存为 C-g 取消命令 C-x C-b 打开当前缓冲区列表","tags":["linux","emacs"],"title":"Emacs快捷键","uri":"https://fhxisdog.github.io/2019/11/emacs%E5%BF%AB%E6%8D%B7%E9%94%AE/","year":"2019"},{"content":"项目中遇到需要将vue打包到spring boot 中的static中，直接访问，不需要使用Nginx来访问nginx.具体做法如下:\n将vue工程放到spring boot工程最外层 修改pom文件  \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.mojo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;exec-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;!--程序打包的时候，利用本地已安装的node环境，同时编译管理后台前端的工程文件--\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;npm-build-background\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;verify\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;exec\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;executable\u0026gt;${npm.command}\u0026lt;/executable\u0026gt; \u0026lt;arguments\u0026gt; \u0026lt;argument\u0026gt;run\u0026lt;/argument\u0026gt; \u0026lt;argument\u0026gt;prod-package\u0026lt;/argument\u0026gt; \u0026lt;/arguments\u0026gt; \u0026lt;workingDirectory\u0026gt;${basedir}/consumable-background\u0026lt;/workingDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-resources-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;!--添加管理后台前端工程的静态文件到jar包中--\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;copy-consumable-background\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;prepare-package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;copy-resources\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;outputDirectory\u0026gt;${basedir}/target/classes/static/background\u0026lt;/outputDirectory\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;${basedir}/consumable-background/dist\u0026lt;/directory\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 配置拦截器(此步可以省略,应为springboot static 路径是默认放开的)  @Override public void addResourceHandlers(org.springframework.web.servlet.config.annotation.ResourceHandlerRegistry registry) { registry.addResourceHandler(\u0026quot;/static/**\u0026quot;) .addResourceLocations(\u0026quot;classpath:/static/\u0026quot;); } ","id":7,"section":"posts","summary":"项目中遇到需要将vue打包到spring boot 中的static中，直接访问，不需要使用Nginx来访问nginx.具体做法如下: 将vue工程放到","tags":["vue","java","spring boot"],"title":"将vue打包到springboot静态资源中","uri":"https://fhxisdog.github.io/2019/09/%E5%B0%86vue%E6%89%93%E5%8C%85%E5%88%B0springboot%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E4%B8%AD/","year":"2019"},{"content":"使用spring boot工程时，虽然官方提供了application.profiles.active参数去激活不同环境，但是如果打包时忘了修改还是比较麻烦的时。可以使用maven插件，自动的更新不同环境的 的配置文件。\n配置方法如下:\n这里列举三个环境:dev,test,prod\nresource目录结构如下(custom-config.properties为自定义的配置文件,区分不同环境也是以dev,test,prod结尾,如:custom-config-dev.properties):\n--- resource --- application.yml --- application-dev.yml --- application-test.yml --- application-prod.yml --- custom-config.properties --- custom-config-dev.properties --- custom-config-test.properties --- custom-config-prod.properties --- application-common.yml  修改pom文件:  \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;dev\u0026lt;/id\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profile.active\u0026gt;dev\u0026lt;/profile.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;test\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profile.active\u0026gt;test\u0026lt;/profile.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;prod\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profile.active\u0026gt;prod\u0026lt;/profile.active\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;build\u0026gt; \u0026lt;finalName\u0026gt;app\u0026lt;/finalName\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;application-*.yml\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;custom-config.properties\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;!-- 是否替换@xx@表示的maven properties属性值 --\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;application.yml\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;application-${profile.active}.yml\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;application-common.yml\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;custom-config.properties\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;filters\u0026gt; \u0026lt;filter\u0026gt; src/main/resources/custom-config-${profile.active}.properties \u0026lt;/filter\u0026gt; \u0026lt;/filters\u0026gt; \u0026lt;/build\u0026gt; 修改配置文件: application.ym文件修改:\nspring: profiles: active: @profile.active@ include: common 这里 @xxx@相当于占位符，打包时会自动替换成dev,test,prod\ncustom-config.propertis文件修改如下:\ncustomA=@customA@ customB=@customB@ custom-config-dev.properties文件:\ncustomA=dev-customA customB=dev-customB 这样就可以替换自定义的配置文件\n","id":8,"section":"posts","summary":"使用spring boot工程时，虽然官方提供了application.profiles.active参数去激活不同环境，但是如果打包时忘了修","tags":["java","spring boot"],"title":"Spring Boot 分环境打包","uri":"https://fhxisdog.github.io/2019/09/spring-boot-%E5%88%86%E7%8E%AF%E5%A2%83%E6%89%93%E5%8C%85/","year":"2019"},{"content":"spring boot 设置contextPath后，如果js中的请求路径不设置，会造成404的问题。 设置方法:\n在html页面header中添加配置:\n\u0026lt;meta name=\u0026quot;ctx\u0026quot; th:content=\u0026quot;${#httpServletRequest.getContextPath()}\u0026quot; \u0026gt; js中引用:\n var ctx = $(\u0026quot;meta[name='ctx']\u0026quot;).attr(\u0026quot;content\u0026quot;); 变量ctx就是contextPath\n","id":9,"section":"posts","summary":"spring boot 设置contextPath后，如果js中的请求路径不设置，会造成404的问题。 设置方法: 在html页面header中添加配置: \u0026lt;meta name=\u0026quot;ctx\u0026quot; th:content=\u0026quot;${#httpServletRequest.getContextPath()}\u0026quot; \u0026gt; j","tags":["java","spring boot"],"title":"Spring Boot Thymeleaf 引用contexpath","uri":"https://fhxisdog.github.io/2019/09/spring-boot-thymeleaf-%E5%BC%95%E7%94%A8contexpath/","year":"2019"},{"content":" 使用华硕的便携笔记本需要安装displaylink驱动，官方又只提供windows驱动，在manjaro上使用需要自己安装驱动，经过研究，安装方法如下: 准备工作  uname -r查看内核版本,输出:4.19.23-1-MANJARO,说明我的内核版本是419,执行pacman -Ss linux-headers查看库中的依赖，执行sudo pacman -S core/liux419-headers安装头文件 安装evdi:yay -S evdi-git\t3 安装displaylink yay -S displaylink  开始配置  装载evdi: sudo modprobe evdi 装载udl: sudo modprobe udl 启用displaylink.sevice: systemctl enable display link 开启displaylink.service:systemctl start displaylink 新增配置文件  /usr/share/X11/xorg.conf.d/20-evdidevice.conf --- Section \u0026quot;OutputClass\u0026quot; Identifier \u0026quot;DisplayLink\u0026quot; MatchDriver \u0026quot;evdi\u0026quot; Driver \u0026quot;modesetting\u0026quot; Option \u0026quot;AccelMethod\u0026quot; \u0026quot;none\u0026quot; EndSection 执行xandr --listproviders,可以看到输出:  Providers: number : 2 Provider 0: id: 0x45 cap: 0xb, Source Output, Sink Output, Sink Offload crtcs: 4 outputs: 2 associated providers: 1 name:Intel Provider 1: id: 0x14d cap: 0x2, Sink Output crtcs: 1 outputs: 1 associated providers: 1 name:modesetting lxrandr开启屏幕  ","id":10,"section":"posts","summary":"使用华硕的便携笔记本需要安装displaylink驱动，官方又只提供windows驱动，在manjaro上使用需要自己安装驱动，经过研究，安","tags":["manjaro","linux"],"title":"Manjaro安装displaylink","uri":"https://fhxisdog.github.io/2019/06/manjaro%E5%AE%89%E8%A3%85displaylink/","year":"2019"},{"content":" 在Docker中，容器之间的链接是一种很常见的操作：它提供了访问其中的某个容器的网络服务而不需要将所需的端口暴露给Docker Host主机的功能。Docker Compose中对该特性的支持同样是很方便的。然而，如果需要链接的容器没有定义在同一个docker-compose.yml中的时候，这个时候就稍微麻烦复杂了点。\n 在不使用Docker Compose的时候，将两个容器链接起来使用—link参数，相对来说比较简单，以nginx镜像为例子：\ndocker run --rm --name test1 -d nginx #开启一个实例test1 docker run --rm --name test2 --link test1 -d nginx #开启一个实例test2并与test1建立链接 这样，test2与test1便建立了链接，就可以在test2中使用访问test1中的服务了。\n如果使用Docker Compose，那么这个事情就更简单了，还是以上面的nginx镜像为例子，编辑docker-compose.yml文件为：\nversion: \u0026quot;3\u0026quot; services: test2: image: nginx depends_on: - test1 links: - test1 test1: image: nginx 最终效果与使用普通的Docker命令docker run xxxx建立的链接并无区别。这只是一种最为理想的情况。\n  如果容器没有定义在同一个docker-compose.yml文件中，应该如何链接它们呢？ 又如果定义在docker-compose.yml文件中的容器需要与docker run xxx启动的容器链接，需要如何处理？ 针对这两种典型的情况，下面给出我个人测试可行的办法：   方式一：让需要链接的容器同属一个外部网络 我们还是使用nginx镜像来模拟这样的一个情景：假设我们需要将两个使用Docker Compose管理的nignx容器（test1和test2）链接起来，使得test2能够访问test1中提供的服务，这里我们以能ping通为准。\n首先，我们定义容器test1的docker-compose.yml文件内容为：\nversion: \u0026quot;3\u0026quot; services: test2: image: nginx container_name: test1 networks: - default - app_net networks: app_net: external: true 容器test2内容与test1基本一样，只是多了一个external_links,需要特别说明的是：最近发布的Docker版本已经不需要使用external_links来链接容器，容器的DNS服务可以正确的作出判断，因此如果你你需要兼容较老版本的Docker的话，那么容器test2的docker-compose.yml文件内容为：\nversion: \u0026quot;3\u0026quot; services: test2: image: nginx networks: - default - app_net external_links: - test1 container_name: test2 networks: app_net: external: true 否则的话，test2的docker-compose.yml和test1的定义完全一致，不需要额外多指定一个external_links。相关的问题请参见stackoverflow上的相关问题：docker-compose + external container\n正如你看到的那样，这里两个容器的定义里都使用了同一个外部网络app_net,因此，我们需要在启动这两个容器之前通过以下命令再创建外部网络：\ndocker network create app_net 之后，通过docker-compose up -d命令启动这两个容器，然后执行docker exec -it test2 ping test1,你将会看到如下的输出：\ndocker exec -it test2 ping test1 PING test1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: icmp_seq=0 ttl=64 time=0.091 ms 64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.146 ms 64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.150 ms 64 bytes from 172.18.0.2: icmp_seq=3 ttl=64 time=0.145 ms 64 bytes from 172.18.0.2: icmp_seq=4 ttl=64 time=0.126 ms 64 bytes from 172.18.0.2: icmp_seq=5 ttl=64 time=0.147 ms 证明这两个容器是成功链接了，反过来在test1中pingtest2也是能够正常ping通的。\n如果我们通过docker run \u0026ndash;rm \u0026ndash;name test3 -d nginx这种方式来先启动了一个容器(test3)并且没有指定它所属的外部网络，而需要将其与test1或者test2链接的话，这个时候手动链接外部网络即可：\ndocker network connect app_net test3 这样，三个容器都可以相互访问了。 方式二：更改需要链接的容器的网络模式 通过更改你想要相互链接的容器的网络模式为bridge,并指定需要链接的外部容器（external_links)即可。与同属外部网络的容器可以相互访问的链接方式一不同，这种方式的访问是单向的。\n还是以nginx容器镜像为例子，如果容器实例nginx1需要访问容器实例nginx2，那么nginx2的doker-compose.yml定义为：\nversion: \u0026quot;3\u0026quot; services: nginx2: image: nginx container_name: nginx2 network_mode: bridge 与其对应的，nginx1的docker-compose.yml定义为：\nversion: \u0026quot;3\u0026quot; services: nginx1: image: nginx external_links: - nginx2 container_name: nginx1 network_mode: bridge  需要特别说明的是，这里的external_links是不能省略的，而且nginx1的启动必须要在nginx2之后，否则可能会报找不到容器nginx2的错误。\n 接着我们使用ping来测试下连通性：\n$ docker exec -it nginx1 ping nginx2 # nginx1 to nginx2 PING nginx2 (172.17.0.4): 56 data bytes 64 bytes from 172.17.0.4: icmp_seq=0 ttl=64 time=0.141 ms 64 bytes from 172.17.0.4: icmp_seq=1 ttl=64 time=0.139 ms 64 bytes from 172.17.0.4: icmp_seq=2 ttl=64 time=0.145 ms $ docker exec -it nginx2 ping nginx1 #nginx2 to nginx1 ping: unknown host 以上也能充分证明这种方式是属于单向联通的。\n在实际应用中根据自己的需要灵活的选择这两种链接方式，如果想偷懒的话，大可选择第二种。不过我更推荐第一种，不难看出无论是联通性还是灵活性，较为更改网络模式的第二种都更为友好。\n 本文转载自夏末的博客\n ","id":11,"section":"posts","summary":"在Docker中，容器之间的链接是一种很常见的操作：它提供了访问其中的某个容器的网络服务而不需要将所需的端口暴露给Docker Host主机的","tags":["docker"],"title":"Docker Compose：链接外部容器的几种方式","uri":"https://fhxisdog.github.io/2019/06/docker-compose%E9%93%BE%E6%8E%A5%E5%A4%96%E9%83%A8%E5%AE%B9%E5%99%A8%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","year":"2019"},{"content":" Alpha：是内部测试版,一般不向外部发布,会有很多Bug.一般只有测试人员使用。 Beta：也是测试版，这个阶段的版本会一直加入新的功能。在Alpha版之后推出。 RC：(Release　Candidate) 顾名思义么 ! 用在软件上就是候选版本。系统平台上就是发行候选版本。RC版不会再加入新的功能了，主要着重于除错。 GA:General Availability,正式发布的版本，在国外都是用GA来说明release版本的。 RTM：(Release to Manufacture)是给工厂大量压片的版本，内容跟正式版是一样的，不过RTM版也有出限制、评估版的。但是和正式版本的主要程序代码都是一样的。 OEM：是给计算机厂商随着计算机贩卖的，也就是随机版。只能随机器出货，不能零售。只能全新安装，不能从旧有操作系统升级。包装不像零售版精美，通常只有一面CD和说明书(授权书)。 RVL：号称是正式版，其实RVL根本不是版本的名称。它是中文版/英文版文档破解出来的。 EVAL：而流通在网络上的EVAL版，与“评估版”类似，功能上和零售版没有区别。 RTL：Retail(零售版)是真正的正式版，正式上架零售版。在安装盘的i386文件夹里有一个eula.txt，最后有一行EULAID，就是你的版本。比如简体中文正式版是EULAID:WX.4_PRO_RTL_CN，繁体中文正式版是WX.4_PRO_RTL_TW。其中：如果是WX.开头是正式版，WB.开头是测试版。_PRE，代表家庭版；_PRO，代表专业版。 α、β、λ常用来表示软件测试过程中的三个阶段，α是第一阶段，一般只供内部测试使用；β是第二个阶段，已经消除了软件中大部分的不完善之处，但仍有可能还存在缺陷和漏洞，一般只提供给特定的用户群来测试使用；λ是第三个阶段，此时产品已经相当成熟，只需在个别地方再做进一步的优化处理即可上市发行。  ","id":12,"section":"posts","summary":"Alpha：是内部测试版,一般不向外部发布,会有很多Bug.一般只有测试人员使用。 Beta：也是测试版，这个阶段的版本会一直加入新的功能。在","tags":["orther"],"title":"Alpha、Beta、RC、GA版本的区别","uri":"https://fhxisdog.github.io/2019/06/alphabetarcga%E7%89%88%E6%9C%AC%E7%9A%84%E5%8C%BA%E5%88%AB/","year":"2019"},{"content":"服务启动 本地单机启动 下载源码 从github上下载源码方式: git clone https://github.com/alibaba/nacos.git cd nacos/ mvn -Prelease-nacos clean install -U ls -al distribution/target/ // change the $version to your actual path cd distribution/target/nacos-server-$version/nacos/bin 下载编译后压缩包方式 从 最新稳定版本 下载 nacos-server-$version.zip 包\n unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gz cd nacos/bin 启动服务 Linux/Unix/Mac sh startup.sh -m standalone windows cmd startup.cmd 或者双击startup.cmd运行文件。\n测试 浏览器访问:localhost:8848/nacos(默认用户名/密码:nacos/nacos)\n单机无数据库docker启动 下载镜像 docker pull nacos/nacos-server 启动docker docker run -d --name nacos -e PREFER_HOST_NAME=hostname -e MODE=standalone -e SPRING_DATASOURCE_PLATFORM=empty -p 8848:8848 nacos/nacos-server docker mysql启动 新建nacos-standalone文件夹，新建standalone.env文件: PREFER_HOST_NAME=hostname MODE=standalone SPRING_DATASOURCE_PLATFORM=mysql DB.NUM=1 MYSQL_MASTER_SERVICE_HOST=iotechina-dev-mysql-5.7.26 MYSQL_MASTER_SERVICE_DB_NAME=nacos MYSQL_MASTER_SERVICE_PORT=3306 MYSQL_MASTER_SERVICE_USER=root MYSQL_MASTER_SERVICE_PASSWORD=you know 将mysql连接到nacos网络 docker network create nacos docker network connect nacos iotechina-dev-mysql-5.7.26 启动 docker run -d --name nacos --env-file=standalone.env --network nacos -p 8848:8848 nacos/nacos-server docker-compose启动 新建nacos文件夹 新建docker-compose.yml文件 version: \u0026quot;3\u0026quot; networks: nacos: external: true services: nacos1: hostname: nacos1 container_name: nacos1 image: nacos/nacos-server:latest volumes: - ./cluster-logs/nacos1:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - \u0026quot;8848:8848\u0026quot; - \u0026quot;9555:9555\u0026quot; env_file: - ./env/nacos-hostname.env external_links: - iotechina-dev-mysql-5.7.26 networks: - nacos restart: on-failure nacos2: hostname: nacos2 image: nacos/nacos-server:latest container_name: nacos2 volumes: - ./cluster-logs/nacos2:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - \u0026quot;8849:8848\u0026quot; external_links: - iotechina-dev-mysql-5.7.26 env_file: - ./env/nacos-hostname.env restart: on-failure networks: - nacos nacos3: hostname: nacos3 image: nacos/nacos-server:latest container_name: nacos3 volumes: - ./cluster-logs/nacos3:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - \u0026quot;8850:8848\u0026quot; external_links: - iotechina-dev-mysql-5.7.26 env_file: - ./env/nacos-hostname.env restart: on-failure networks: - nacos 复制官方docker配置到 nacos目录对应的文件夹 编辑nacos/env/nacos-hostname.env #nacos dev env PREFER_HOST_MODE=hostname NACOS_SERVERS=nacos1:8848 nacos2:8848 nacos3:8848 MYSQL_MASTER_SERVICE_HOST=iotechina-dev-mysql-5.7.26 MYSQL_MASTER_SERVICE_DB_NAME= DB_NAME MYSQL_MASTER_SERVICE_PORT=3306 MYSQL_SLAVE_SERVICE_HOST=iotechina-dev-mysql-5.7.26 MYSQL_SLAVE_SERVICE_PORT=3306 MYSQL_MASTER_SERVICE_USER=you know MYSQL_MASTER_SERVICE_PASSWORD=you know mysql 连接 nacos network docker network connect nacos iotechina-dev-mysql-5.7.26 启动 docker-compose up -d 单机集群mysql启动 复制mysql驱动 在nacos/plugins/新建文件夹mysql,复制对应数据库的jar驱动到这个文件夹\n修改配置文件 编辑nacos/application.properties文件,加入如下内容:\nspring.datasource.platform=mysql db.num=1 db.url.0=jdbc:mysql://dev.iotechina.com:13306/nacos?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true db.user=you know db.password=you know 编辑nacos/conf/cluster.conf(如果没有新建一个)\n192.168.0.118:8848 #注意这里和`conf/application.properties`中的`server.port`相对应 192.168.0.118:8847 192.168.0.118:8846 启动 sh startup.sh spring cloud 版本对应关系 由于nacos还没有纳入spring cloud体系，所以需要手动管理依赖关系。\n版本对应关系:版本说明 Wiki\n服务发现 Demo 启动nacos-server 配置应用 新建两个spring-boot应用:service-consumer,service-provider 分别配置两个应用 引入pom依赖:\n\u0026lt;!--注意这里版本依赖关系，根据自己的springcloud版本引入对应的版本--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-nacos-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 启动类添加注解：@EnableDiscoveryClient\n编辑application.properties:\nspring.application.name=${application-name} #应用名称，根据自己需要填写 spring.cloud.nacos.discovery.server-addr=dev.iotechina.com:8848 使用feign进行调用测试 配置中心 Demo 启动nacos-server 添加配置 打开nacos网页端: 配置管理-\u0026gt;配置列表-\u0026gt;点击加号添加配置\nData ID: service-consumer.properties #注意，此处一定要有.properties，并且名字和应用的${spring.application.name}一致 Group : DEFAULT_GROUP 配置格式: properties 配置内容: server.port=8845 点击发布\n应用配置 引入pom依赖\n\u0026lt;!--注意这里版本依赖关系，根据自己的springcloud版本引入对应的版本--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-nacos-version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 编辑bootstrap.properties:\nspring.application.name=service-consumer spring.cloud.nacos.config.server-addr=dev.iotechina.com:8848 启动应用，发现启动端口已变为8845\n2019-05-29 15:13:35.493 INFO 1593 --- [ main] o.s.c.a.n.c.NacosPropertySourceBuilder : Loading nacos data, dataId: 'service-consumer.properties', group: 'DEFAULT_GROUP' 2019-05-29 15:13:35.494 INFO 1593 --- [ main] b.c.PropertySourceBootstrapConfiguration : Located property source: CompositePropertySource {name='NACOS', propertySources=[NacosPropertySource {name='service-consumer.properties'}]} 2019-05-29 15:13:35.498 INFO 1593 --- [ main] c.d.n.NacosConsumerApplication : No active profile set, falling back to default profiles: default 2019-05-29 15:13:35.974 INFO 1593 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=825b518e-28f8-3c01-8579-67d040c18160 2019-05-29 15:13:35.991 INFO 1593 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'com.demo.nacosconsumer.feign.EchoFeign' of type [org.springframework.cloud.openfeign.FeignClientFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2019-05-29 15:13:36.033 INFO 1593 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6f581f58] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2019-05-29 15:13:36.188 INFO 1593 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8845 (http) profile粒度的配置 nacos控制台新建service-consumer-test.properties文件，写入内容server.port=8847。\n编辑bootstrap.properties:\nspring.profiles.active=test 重启应用，查看端口变化\n自定义 namespace 的配置 Nacos 的 Namespace 的概念：\n 用于进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的 Group 或 Data ID 的配置。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。\n 在没有明确指定 ${spring.cloud.nacos.config.namespace} 配置的情况下， 默认使用的是 Nacos 上 Public 这个namespae。如果需要使用自定义的命名空间，可以通过以下配置来实现：\nspring.cloud.nacos.config.namespace=b3404bc0-d7dc-4855-b519-570ed34b62d7 *** 该配置必须放在 bootstrap.properties 文件中。此外 spring.cloud.nacos.config.namespace 的值是 namespace 对应的 id，id 值可以在 Nacos 的控制台获取。并且在添加配置时注意不要选择其他的 namespae，否则将会导致读取不到正确的配置。 ***\n自定义 Group 的配置 在没有明确指定 ${spring.cloud.nacos.config.group} 配置的情况下， 默认使用的是 DEFAULT_GROUP 。如果需要自定义自己的 Group，可以通过以下配置来实现：\nspring.cloud.nacos.config.group=DEVELOP_GROUP *** 该配置必须放在 bootstrap.properties 文件中。并且在添加配置时 Group 的值一定要和 spring.cloud.nacos.config.group 的配置值一致。***\n自定义扩展的 Data Id 配置 配置Demo：\nspring.application.name=opensource-service-provider spring.cloud.nacos.config.server-addr=127.0.0.1:8848 # config external configuration # 1、Data Id 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新 spring.cloud.nacos.config.ext-config[0].data-id=ext-config-common01.properties # 2、Data Id 不在默认的组，不支持动态刷新 spring.cloud.nacos.config.ext-config[1].data-id=ext-config-common02.properties spring.cloud.nacos.config.ext-config[1].group=GLOBALE_GROUP # 3、Data Id 既不在默认的组，也支持动态刷新 spring.cloud.nacos.config.ext-config[2].data-id=ext-config-common03.properties spring.cloud.nacos.config.ext-config[2].group=REFRESH_GROUP spring.cloud.nacos.config.ext-config[2].refresh=true 可以看到:\n 通过 spring.cloud.nacos.config.ext-config[n].data-id 的配置方式来支持多个 Data Id 的配置。 通过 spring.cloud.nacos.config.ext-config[n].group 的配置方式自定义 Data Id 所在的组，不明确配置的话，默认是 DEFAULT_GROUP。 通过 spring.cloud.nacos.config.ext-config[n].refresh 的配置方式来控制该 Data Id 在配置变更时，是否支持应用中可动态刷新， 感知到最新的配置值。默认是不支持的。  Note: 多个 Data Id 同时配置时，他的优先级关系是 spring.cloud.nacos.config.ext-config[n].data-id 其中 n 的值越大，优先级越高。\nNote:*** spring.cloud.nacos.config.ext-config[n].data-id 的值必须带文件扩展名，文件扩展名既可支持 properties，又可以支持 yaml/yml。 此时 spring.cloud.nacos.config.file-extension 的配置对自定义扩展配置的 Data Id 文件扩展名没有影响。***\n为了更加清晰的在多个应用间配置共享的 Data Id ，你可以通过以下的方式来配置：\nspring.cloud.nacos.config.shared-dataids=bootstrap-common.properties,all-common.properties spring.cloud.nacos.config.refreshable-dataids=bootstrap-common.properties 可以看到：\n 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享 Data Id 的配置，多个之间用逗号隔开。 通过 spring.cloud.nacos.config.refreshable-dataids 来支持哪些共享配置的 Data Id 在配置变化时，应用中是否可动态刷新， 感知到最新的配置值，多个 Data Id 之间用逗号隔开。如果没有明确配置，默认情况下所有共享配置的 Data Id 都不支持动态刷新。  Note:*** 通过 spring.cloud.nacos.config.shared-dataids 来支持多个共享配置的 Data Id 时， 多个共享配置间的一个优先级的关系我们约定：按照配置出现的先后顺序，即后面的优先级要高于前面。 ***\nNote:*** 通过 1spring.cloud.nacos.config.shared-dataids1 来配置时，Data Id 必须带文件扩展名，文件扩展名既可支持 properties，也可以支持 yaml/yml。 此时 spring.cloud.nacos.config.file-extension1 的配置对自定义扩展配置的 Data Id 文件扩展名没有影响。 ***\nNote:spring.cloud.nacos.config.refreshable-dataids 给出哪些需要支持动态刷新时，Data Id 的值也必须明确给出文件扩展名。\n配置的优先级 Spring Cloud Alibaba Nacos Config 目前提供了三种配置能力从 Nacos 拉取相关的配置\n A: 通过 spring.cloud.nacos.config.shared-dataids 支持多个共享 Data Id 的配置 B: 通过 spring.cloud.nacos.config.ext-config[n].data-id 的方式支持多个扩展 Data Id 的配置 C: 通过内部相关规则(应用名、应用名+ Profile )自动生成相关的 Data Id 配置  当三种方式共同使用时，他们的一个优先级关系是:A \u0026lt; B \u0026lt; C\n遇到的问题   登陆错误:`io.jsonwebtoken.security.SignatureException: Unable to obtain JCA MAC algorithm \u0026lsquo;HmacSHA256\u0026rsquo;: Algorithm HmacSHA256 not available\n解决方法:\n1.由于是我yay -S 安装的jdk，所以没有JAVA_HOME，解决方案，控制台先执行export JAVA_HOME=/usr/lib/jvm/openjdk1.8.1 然后执行 sh startup.sh -m standalone\n2.设置JAVA_HOME环境变量\n参考连接:\nhttps://github.com/alibaba/nacos/issues/711\nhttps://github.com/jwtk/jjwt/issues/429\n  查看服务列表跳会登陆页，浏览器控制台提示401错误\n解决方法:\n清除浏览器缓存\n  集群模式，cluster.conf中的ip写127.0.0.1：8848报错\n  解决方法:\n写ip地址，例如:`192.168.0.118` ","id":13,"section":"posts","summary":"服务启动 本地单机启动 下载源码 从github上下载源码方式: git clone https://github.com/alibaba/nacos.git cd nacos/ mvn -Prelease-nacos clean install -U ls -al distribution/target/ // change the $version to your actual path cd distribution/target/nacos-server-$version/nacos/bin 下载编译后压缩包方式 从 最新稳定版本 下","tags":["java","nacos","spring cloud"],"title":"nacos使用指南","uri":"https://fhxisdog.github.io/2019/05/nacos%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","year":"2019"},{"content":"运行 单机运行  下载最新release包 解压，sh ${skywalkingpath}/bin/startup.sh 在springboot启动命令前加入启动参数  -javaagent:${path}/skywalking-agent.jar #path为skywalking解压的agent目录  访问localhost:8080查看结果  docker 运行 前置条件 下载 下载最新release包并解压\n构建docker bridge dcoker network create skywalking 使用数据库 ElasticSearch 启动es docker run -p 9200:9200 -p 9300:9300 -e \u0026quot;discovery.type=single-node\u0026quot; docker.elastic.co/elasticsearch/elasticsearch:6.4.3 #skywalking目前只支持6.x(6.1.0版本) 初始化数据库 编辑 ${path}/apache-skywalking-bin/config/appliccation.yml\nstorage: #elasticsearch: nameSpace: ${SW_NAMESPACE:\u0026quot;\u0026quot;} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:dev.iotechina.com:9201} #user: ${SW_ES_USER:\u0026quot;\u0026quot;} #password: ${SW_ES_PASSWORD:\u0026quot;\u0026quot;} indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2} indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} #Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests bulkSize: ${SW_STORAGE_ES_BULK_SIZE:20} # flush the bulk every 20mb flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} 执行\nsh ${path}/apache-skywalking-bin/bin/oapServiceInit.sh 执行\n tail -f ${path}/apache-skywalking-bin/config/skywalking-oap-server.log 等待执行完成\nmysql 复制mysql驱动到${path}/apapch-skywalking-bin/oap-libs 编辑 ${path}/apache-skywalking-bin/config/appliccation.yml  storage: mysql: metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000} 编辑${path}/apache-skywalking-bin/config/datasource-setting.properties  jdbcUrl=jdbc:mysql://dev.iotechina.com:3316/sky_walking dataSource.user= you know dataSource.password=you know dataSource.cachePrepStmts=true dataSource.prepStmtCacheSize=250 dataSource.prepStmtCacheSqlLimit=2048 dataSource.useServerPrepStmts=true dataSource.useLocalSessionState=true dataSource.rewriteBatchedStatements=true dataSource.cacheResultSetMetadata=true dataSource.cacheServerConfiguration=true dataSource.elideSetAutoCommits=true dataSource.maintainTimeStats=false sh ${path}/apache-skywalking-bin/bin/oapServiceInit.sh 执行\ntail -f ${path}/apache-skywalking-bin/config/skywalking-oap-server.log 等待执行完成\n构建OAP镜像 准备条件 复制oap-libs文件夹到/root/skywalking/oap目录\n复制config目录到/root/skywalking/oap目录\n编辑config目录下log4j2.xml：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;Configuration status=\u0026quot;INFO\u0026quot;\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026quot;Console\u0026quot; target=\u0026quot;SYSTEM_OUT\u0026quot;\u0026gt; \u0026lt;PatternLayout charset=\u0026quot;UTF-8\u0026quot; pattern=\u0026quot;%d - %c -%-4r [%t] %-5p %x - %m%n\u0026quot;/\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;logger name=\u0026quot;org.eclipse.jetty\u0026quot; level=\u0026quot;INFO\u0026quot;/\u0026gt; \u0026lt;logger name=\u0026quot;org.apache.zookeeper\u0026quot; level=\u0026quot;INFO\u0026quot;/\u0026gt; \u0026lt;logger name=\u0026quot;org.elasticsearch.common.network.IfConfig\u0026quot; level=\u0026quot;INFO\u0026quot;/\u0026gt; \u0026lt;logger name=\u0026quot;io.grpc.netty\u0026quot; level=\u0026quot;INFO\u0026quot;/\u0026gt; \u0026lt;logger name=\u0026quot;org.apache.skywalking.oap.server.receiver.istio.telemetry\u0026quot; level=\u0026quot;DEBUG\u0026quot;/\u0026gt; \u0026lt;Root level=\u0026quot;INFO\u0026quot;\u0026gt; \u0026lt;AppenderRef ref=\u0026quot;Console\u0026quot;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; 编写启动脚本 新建docker-entrypoint.sh:\n#!/bin/bash set -ex CLASSPATH=\u0026quot;config:$CLASSPATH\u0026quot; for i in oap-libs/*.jar do CLASSPATH=\u0026quot;$i:$CLASSPATH\u0026quot; done exec java -Xms256M -Xmx512M -classpath $CLASSPATH org.apache.skywalking.oap.server.starter.OAPServerStartUp \u0026quot;$@\u0026quot; 编写Dockerfile 新建Dcokerfile:\nFROM openjdk:8-jre-alpine RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo 'Asia/Shanghai' \u0026gt;/etc/timezone #设置时区，不然ui会查不到数据 WORKDIR /skywalking RUN apk add --no-cache \\ bash COPY docker-entrypoint.sh /skywalking COPY oap-libs/ /skywalking/oap-libs EXPOSE 12800 11800 ENTRYPOINT [\u0026quot;sh\u0026quot;,\u0026quot;docker-entrypoint.sh\u0026quot;] 构建镜像 dcoker build -t {your tag} . 启动容器 docker run --name skywalking-oap -d -v /root/skywalking/oap/config:/skywalking/config -p 12800:12800 -p 11800:11800 --network skywalking {your tag} 构建ui镜像 准备条件 复制webapp文件夹到/root/skywalking/ui目录\n在/root/skywalking/ui/webapp目录下新建文件logback.xml：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;include resource=\u0026quot;org/springframework/boot/logging/logback/base.xml\u0026quot; /\u0026gt; \u0026lt;/configuration\u0026gt; 编写启动脚本: 新建docker-entrypoint.sh：\n#!/bin/bash exec java -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -jar /skywalking/webapp/skywalking-webapp.jar --logging.config=/skywalking/webapp/logback.xml --spring.config.location=/skywalking/webapp/webapp.yml \u0026quot;$@\u0026quot; 编写Dockerfile: 新建Dockerfile：\nFROM openjdk:8-jre-alpine RUN apk add --no-cache \\ bash RUN echo 'Asia/Shanghai' \u0026gt;/etc/timezone WORKDIR /skywalking COPY docker-entrypoint.sh . EXPOSE 8080 ENTRYPOINT [\u0026quot;bash\u0026quot;, \u0026quot;docker-entrypoint.sh\u0026quot;] 构建镜像 dcoker build -t {your tag} . 修改配置 编辑/root/skywalking/webapp/webapp.yml\nserver: port: 8080 collector: path: /graphql ribbon: ReadTimeout: 10000 # Point to all backend's restHost:restPort, split by , listOfServers: skywalking-oap:12800 #服务端地址 security: user: admin: password: you know 启动容器  docker run --name skywalking-ui -d -v /root/skywalking/ui/webapp:/skywalking/webapp -p 8080:8080 --network skywalking {your tag} 修改agent配置 修改 path/agent/config/agent.config：\ncollector.backend_service=${SW_AGENT_COLLECTOR_BACKEND_SERVICES:你的服务器地址:11800} 启动应用并访问服务器8080端口查看信息 连接elasticsearch(基于上一步docker运行skywalking) 启动esasticsearch  docker run -d --name es-skywalking -p 9201:9200 -p 9301:9300 -e \u0026quot;discovery.type=single-node\u0026quot; elasticsearch:6.4.3 #skywalking 6.1.0 貌似不支持 es 7.x的版本 初始化elasticsearch 修改本地 path/config/application.yml:\nstorage: elasticsearch: #nameSpace: ${SW_NAMESPACE:\u0026quot;\u0026quot;} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:你的服务器地址:9201} #user: ${SW_ES_USER:\u0026quot;\u0026quot;} #password: ${SW_ES_PASSWORD:\u0026quot;\u0026quot;} indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2} indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests bulkSize: ${SW_STORAGE_ES_BULK_SIZE:20} # flush the bulk every 20mb flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} 执行\nsh {path}/bin/oapServiceInit.sh 将es接入 skywalking bridge docker network connect skywalking es-skywalking 修改skywalking配置文件 修改/root/skywalking/oap/config/application.yml：\nstorage: elasticsearch: #nameSpace: ${SW_NAMESPACE:\u0026quot;\u0026quot;} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:es-skywalking:9200} #user: ${SW_ES_USER:\u0026quot;\u0026quot;} #password: ${SW_ES_PASSWORD:\u0026quot;\u0026quot;} indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2} indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests bulkSize: ${SW_STORAGE_ES_BULK_SIZE:20} # flush the bulk every 20mb flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} 重启skywalking-oap docker restart skywalking-oap plugin使用 apm-toolkit-logback-1.x 项目pom文件引入  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.skywalking\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;apm-toolkit-logback-1.x\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;6.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 编辑logback.yml  \u0026lt;appender name=\u0026quot;console\u0026quot; class=\u0026quot;ch.qos.logback.core.ConsoleAppender\u0026quot;\u0026gt; \u0026lt;encoder class=\u0026quot;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026quot;\u0026gt; \u0026lt;layout class=\u0026quot;org.apache.skywalking.apm.toolkit.log.logback.v1.x.TraceIdPatternLogbackLayout\u0026quot;\u0026gt; \u0026lt;Pattern\u0026gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%tid] [%thread] %-5level %logger{36} -%msg%n\u0026lt;/Pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; ","id":14,"section":"posts","summary":"运行 单机运行 下载最新release包 解压，sh ${skywalkingpath}/bin/startup.sh 在springboot启动命令前加入启动参数 -javaagent:${path}/skywalking-agent.jar #path为skywalking解压的agen","tags":["java","skywalking","spring cloud"],"title":"skywalking使用指南","uri":"https://fhxisdog.github.io/2019/05/skywalking%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","year":"2019"},{"content":"装了manjaro的i3wm桌面环境后，发现外界显示器无法显示。搜索资料后发现解决方法如下。\n查看设备输入 终端输入:\nxrandr 可以看到结果如下，其中 eDP1是我笔记本自带的屏幕，HDMI1就是我外接的显示器。\nScreen 0: minimum 8 x 8, current 1920 x 1080, maximum 32767 x 32767 eDP1 connected primary 1920x1080+0+0 (normal left inverted right x axis y axis) 310mm x 170mm 1920x1080 60.05*+ 59.93 1680x1050 59.88 1400x1050 59.98 1600x900 60.00 59.95 59.82 1280x1024 60.02 1400x900 59.96 59.88 1280x960 60.00 1368x768 60.00 59.88 59.85 1280x800 59.81 59.91 1280x720 59.86 60.00 59.74 1024x768 60.00 1024x576 60.00 59.90 59.82 960x540 60.00 59.63 59.82 800x600 60.32 56.25 864x486 60.00 59.92 59.57 640x480 59.94 720x405 59.51 60.00 58.99 640x360 59.84 59.32 60.00 DP1 disconnected (normal left inverted right x axis y axis) HDMI1 connected (normal left inverted right x axis y axis) 1920x1080 60.00 + 50.00 59.94 1920x1080i 60.00 50.00 59.94 1600x900 60.00 1280x1024 75.02 60.02 1152x864 75.00 1280x720 60.00 50.00 59.94 1024x768 75.03 60.00 800x600 75.00 60.32 720x576 50.00 720x576i 50.00 720x480 60.00 59.94 720x480i 60.00 59.94 640x480 75.00 60.00 59.94 720x400 70.08 HDMI2 disconnected (normal left inverted right x axis y axis) VIRTUAL1 disconnected (normal left inverted right x axis y axis) 双屏设置  设置主屏幕   xrandr --auto --output eDP1 --primary ---auto：可以自动启用关闭的屏幕。 ---primary：设置主屏。  复制模式   xrandr --auto --output eDP1 --pos 0x0 --mode 1920x1080 --output HDMI1 --same-as eDP1 ---pos：起始位置，x。 ---same-as：与eDP1输出保持一致。  扩展模式   xrandr --auto --output eDP1 --pos 0x0 --mode 1920x1080 --primary --output HDMI1 --mode 1024x768 --right-of eDP1 --right-of：HDMI1的起始位置在eDP1的右边。 命令的结果就是HDM1 会在 eDP1 的右边，eDP1 为主屏，另外位置的参数还有 \u0026ndash;left-of, \u0026ndash;above, \u0026ndash;below 等。 如果需要自定义两个屏幕的位置， 可以通过计算每个屏幕的分辨率， 用 \u0026ndash;pos 参数来指定每个屏幕显示的位置。\n 单屏模式   xrandr --output eDP1 --pos 0x0 --mode 1920x1080 --primary --output VGA1 --off --off:关闭某个屏幕.  自定义模式  另外屏幕的旋转, 镜像和缩放可以分别使用 --rotate, --reflect 和 --scale 参数来实现.  永久保存  如果需要永久保存配置，可以通过更改/etc/X11/xorg.conf或者/etc/X11/xorg.conf.d/****进行保存。 常用命令  外接显示器(\u0026ndash;auto:最高分辨率)，与笔记本液晶屏幕显示同样内容（克隆）  xrandr --output HDMI1 --same-as eDP1 auto  打开外接显示器(分辨率为1920x1080)，与笔记本液晶屏幕显示同样内容（克隆）   xrandr --output HDMI1 --same-as eDMP1 --mode 1920x1020  打开外接显示器(\u0026ndash;auto:最高分辨率)，设置为右侧扩展屏幕   xrandr --output HDMI1 --right-of eDP1 --auto  关闭外接显示器   xrandr --output HDMI1 --off  打开外接显示器，同时关闭笔记本液晶屏幕（只用外接显示器工作）   xrandr --output HDMI1 --auto --output eDP1 --off  关闭外接显示器，同时打开笔记本液晶屏幕 （只用笔记本液晶屏）   xrandr --output HDMI1 --off --output eDP1 --auto 参考连接 Arch Wiki\n使用Xrandr设置单屏和双屏\n","id":15,"section":"posts","summary":"装了manjaro的i3wm桌面环境后，发现外界显示器无法显示。搜索资料后发现解决方法如下。 查看设备输入 终端输入: xrandr 可以看到结果如下，其中 e","tags":["manjaro","linux","i3wm"],"title":"Manjaro I3wm接入外接显示器不显示","uri":"https://fhxisdog.github.io/2019/05/manjaro-i3wm%E6%8E%A5%E5%85%A5%E5%A4%96%E6%8E%A5%E6%98%BE%E7%A4%BA%E5%99%A8%E4%B8%8D%E6%98%BE%E7%A4%BA/","year":"2019"},{"content":"manjaro的i3wm版本默认的mod键是super(就是windows键)，为了拯救我的小拇指，所以使用xmodmap将super键和CapsLock互换位置。\n 创建自己的映射表 xmodmap -pke \u0026gt; ~/.Xmodmap 创建映射 编辑～/.Xmodmap,在底部加入:\nremove Lock = Caps_Lock remove Mod4 = Super_L keysym Super_L = Caps_Lock keysym Caps_Lock = Super_L add Lock = Caps_Lock add Mod4 = Super_L 测试: xmodmap ~/.Xmodmap 设置开机启动: 默认系统读取的就是$HOME/.Xmodmap\n参考连接 arch-wiki\nhttps://www.linuxidc.com/Linux/2013-05/84542.htm\n","id":16,"section":"posts","summary":"manjaro的i3wm版本默认的mod键是super(就是windows键)，为了拯救我的小拇指，所以使用xmodmap将super键和C","tags":["modmap","linux","i3wm"],"title":"Linux使用modmap替换super和CapsLock位置","uri":"https://fhxisdog.github.io/2019/05/linux%E4%BD%BF%E7%94%A8modmap%E6%9B%BF%E6%8D%A2super%E5%92%8Ccapslock%E4%BD%8D%E7%BD%AE/","year":"2019"},{"content":"问题描述 使用pacmanfm在地址栏输入:smb://fhxisdog-win/temp访问windows共享文件夹，提示NO FILE OR DIRECTIONARY\n在命令行使用命令:smbclient -L fhxisdog-win -U% 提示:NT_STATUS_ACCESS_DENIED\n使用:smbclient -L fhxisdog-win -m SMB2可以访问\n解决方法 编辑 /etc/samba/smb.conf:在[gloabl]下加入:\nmin protocOl = SMB2 max protocol = SMB2 client min protocol = SMB2 client max protocol = SMB2 smb简介  服务器消息块（Server Message Block，缩写为SMB），又称网络文件共享系统（Common Internet File System，缩写为CIFS, /ˈsɪfs/），一种应用层网络传输协议，由微软开发，主要功能是使网络上的机器能够共享计算机文件、打印机、串行端口和通讯等资源。它也提供经认证的行程间通信机能。它主要用在装有Microsoft Windows的机器上，在这样的机器上被称为Microsoft Windows Network。\n  经过Unix服务器厂商重新开发后，它可以用于连接Unix服务器和Windows客户机，执行打印和文件共享等任务。\n  与功能类似的网络文件系统（NFS）相比，NFS的消息格式是固定长度，而CIFS的消息格式大多数是可变长度，这增加了协议的复杂性。CIFS消息一般使用NetBIOS或TCP协议发送，分别使用不同的端口139或445，当前倾向于使用445端口。CIFS的消息包括一个信头（32字节）和消息体（1个或多个，可变长）。\n 参考连接:wiki\n","id":17,"section":"posts","summary":"问题描述 使用pacmanfm在地址栏输入:smb://fhxisdog-win/temp访问windows共享文件夹，提示NO FILE OR DIRECTIONARY 在命令行","tags":["smb","linux"],"title":"Smb无法连接windows共享文件夹","uri":"https://fhxisdog.github.io/2019/05/smb%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5windows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/","year":"2019"},{"content":"本文所用到的工具  shadowsocks-libev privoxy gfwlist2privoxy  shadowsocks-libev安装配置 下载安装:sudo pacman -S shadowsocks-libev\n配置:\n 在/etc/shadowsocks/下新建config.json文件 编辑config.json：  { \u0026#34;server\u0026#34;:\u0026#34;xxxxxx\u0026#34;, #服务器IP \u0026#34;server_port\u0026#34;:xxx, #服务器端口 \u0026#34;local_address\u0026#34;:\u0026#34;127.0.0.1\u0026#34;, #本地监听IP \u0026#34;local_port\u0026#34;:1080, #本地监听端口 \u0026#34;password\u0026#34;:\u0026#34;xxx\u0026#34;, #密码 \u0026#34;method\u0026#34;:\u0026#34;xxx\u0026#34;, #加密方式 \u0026#34;fast_open\u0026#34;:false, # tcp_fastopen \u0026#34;timeout\u0026#34;:1000, #超时时间 \u0026#34;workers\u0026#34;:1 #workder进程数 }  启动ss-local: ss-local -c /etc/shadowsocks/config.json 测试:curl -x socks5://127.0.0.1:1080 http://www.google.com 设置守护进程启动:systemctl start shadowsocks-libev@config ** 注意：这里@config是指 /etc/shadowsocks/下面的配置文件 ** 设置开机自启动: systemctl enable shadows-libev@config  privoxy+gfwlist2privoxy安装配置 下载privoxy：sudo pacman -S privoxy\n获取 gfwlist2privoxy 脚本:curl -skL https://raw.github.com/zfl9/gfwlist2privoxy/master/gfwlist2privoxy -o gfwlist2privoxy\n生成 gfwlist.action 文件: bash gfwlist2privoxy '127.0.0.1:1080' \n拷贝至 privoxy 配置目录:cp -af gfwlist.action /etc/privoxy/\n加载 gfwlist.action 文件 echo 'actionsfile gfwlist.action' \u0026gt;\u0026gt; /etc/privoxy/config\n启动privoxy:sysemctl start privoxy\n设置开机自启动: systemctl enable privoxy\n测试:\n 设置环境变量:  # 8118 为privoxy默认监听端口 export http_proxy = http:127.0.0.1:8118 export https_proxy = http:127.0.0.1:8118  curl测试: curl www.google.com   设置环境变量 编辑 /etc/prifile,加入以下两行:\nexport http_proxy = http:127.0.0.1:8118 export https_proxy = http:127.0.0.1:8118 重启，打开浏览器验证\n","id":18,"section":"posts","summary":"本文所用到的工具 shadowsocks-libev privoxy gfwlist2privoxy shadowsocks-libev安装配置 下载安装:sudo pacman -S shadowsocks-libev 配置: 在/etc/shadowsocks/下新建co","tags":["linux","shadowsocks","vpn"],"title":"Shadowsocks-libev+privoxy+gfwlist2privoxy","uri":"https://fhxisdog.github.io/2019/05/shadowsocks-libev-privoxy/","year":"2019"},{"content":"转自:https://www.ibm.com/developerworks/cn/java/j-lo-just-in-time/\nJIT 简介 JIT 是 just in time 的缩写, 也就是即时编译编译器。使用即时编译器技术，能够加速 Java 程序的执行速度。下面，就对该编译器技术做个简单的讲解。\n首先，我们大家都知道，通常通过 javac 将程序源代码编译，转换成 java 字节码，JVM 通过解释字节码将其翻译成对应的机器指令，逐条读入，逐条解释翻译。很显然，经过解释执行，其执行速度必然会比可执行的二进制字节码程序慢很多。为了提高执行速度，引入了 JIT 技术。\n在运行时 JIT 会把翻译过的机器码保存起来，以备下次使用，因此从理论上来说，采用该 JIT 技术可以接近以前纯编译技术。下面我们看看，JIT 的工作过程。\nJIT 编译过程 当 JIT 编译启用时（默认是启用的），JVM 读入.class 文件解释后，将其发给 JIT 编译器。JIT 编译器将字节码编译成本机机器代码，下图展示了该过程。\n图 1. JIT 工作原理图\nHot Spot 编译 当 JVM 执行代码时，它并不立即开始编译代码。这主要有两个原因：\n首先，如果这段代码本身在将来只会被执行一次，那么从本质上看，编译就是在浪费精力。因为将代码翻译成 java 字节码相对于编译这段代码并执行代码来说，要快很多。\n当然，如果一段代码频繁的调用方法，或是一个循环，也就是这段代码被多次执行，那么编译就非常值得了。因此，编译器具有的这种权衡能力会首先执行解释后的代码，然后再去分辨哪些方法会被频繁调用来保证其本身的编译。其实说简单点，就是 JIT 在起作用，我们知道，对于 Java 代码，刚开始都是被编译器编译成字节码文件，然后字节码文件会被交由 JVM 解释执行，所以可以说 Java 本身是一种半编译半解释执行的语言。Hot Spot VM 采用了 JIT compile 技术，将运行频率很高的字节码直接编译为机器指令执行以提高性能，所以当字节码被 JIT 编译为机器码的时候，要说它是编译执行的也可以。也就是说，运行时，部分代码可能由 JIT 翻译为目标机器指令（以 method 为翻译单位，还会保存起来，第二次执行就不用翻译了）直接执行。\n第二个原因是最优化，当 JVM 执行某一方法或遍历循环的次数越多，就会更加了解代码结构，那么 JVM 在编译代码的时候就做出相应的优化。\n我们将在后面讲解这些优化策略，这里，先举一个简单的例子：我们知道 equals() 这个方法存在于每一个 Java Object 中（因为是从 Object class 继承而来）而且经常被覆写。当解释器遇到 b = obj1.equals(obj2) 这样一句代码，它则会查询 obj1 的类型从而得知到底运行哪一个 equals() 方法。而这个动态查询的过程从某种程度上说是很耗时的。\n寄存器和主存 其中一个最重要的优化策略是编译器可以决定何时从主存取值，何时向寄存器存值。考虑下面这段代码：\n清单 1. 主存 or 寄存器测试代码\npublic class RegisterTest { private int sum; public void calculateSum(int n) { for (int i = 0; i \u0026lt; n; ++i) { sum += i; } } } 在某些时刻，sum 变量居于主存之中，但是从主存中检索值是开销很大的操作，需要多次循环才可以完成操作。正如上面的例子，如果循环的每一次都是从主存取值，性能是非常低的。相反，编译器加载一个寄存器给 sum 并赋予其初始值，利用寄存器里的值来执行循环，并将最终的结果从寄存器返回给主存。这样的优化策略则是非常高效的。但是线程的同步对于这种操作来说是至关重要的，因为一个线程无法得知另一个线程所使用的寄存器里变量的值，线程同步可以很好的解决这一问题，有关于线程同步的知识，我们将在后续文章中进行讲解。\n寄存器的使用是编译器的一个非常普遍的优化。\n回到之前的例子，JVM 注意到每次运行代码时，obj1 都是 java.lang.String 这种类型，那么 JVM 生成的被编译后的代码则是直接调用 String.equals() 方法。这样代码的执行将变得非常快，因为不仅它是被编译过的，而且它会跳过查找该调用哪个方法的步骤。\n当然过程并不是上面所述这样简单，如果下次执行代码时，obj1 不再是 String 类型了，JVM 将不得不再生成新的字节码。尽管如此，之后执行的过程中，还是会变的更快，因为同样会跳过查找该调用哪个方法的步骤。这种优化只会在代码被运行和观察一段时间之后发生。这也就是为什么 JIT 编译器不会理解编译代码而是选择等待然后再去编译某些代码片段的第二个原因。\n初级调优：客户模式或服务器模式 JIT 编译器在运行程序时有两种编译模式可以选择，并且其会在运行时决定使用哪一种以达到最优性能。这两种编译模式的命名源自于命令行参数（eg: -client 或者 -server）。JVM Server 模式与 client 模式启动，最主要的差别在于：-server 模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。原因是：当虚拟机运行在-client 模式的时候，使用的是一个代号为 C1 的轻量级编译器，而-server 模式启动的虚拟机采用相对重量级代号为 C2 的编译器。C2 比 C1 编译器编译的相对彻底，服务起来之后，性能更高。\n通过 java -version 命令行可以直接查看当前系统使用的是 client 还是 server 模式。例如：\n图 2. 查看编译模式\n中级编译器调优 大多数情况下，优化编译器其实只是选择合适的 JVM 以及为目标主机选择合适的编译器（-cient，-server 或是-xx:+TieredCompilation）。多层编译经常是长时运行应用程序的最佳选择，短暂应用程序则选择毫秒级性能的 client 编译器。\n优化代码缓存 当 JVM 编译代码时，它会将汇编指令集保存在代码缓存。代码缓存具有固定的大小，并且一旦它被填满，JVM 则不能再编译更多的代码。\n我们可以很容易地看到如果代码缓存很小所具有的潜在问题。有些热点代码将会被编译，而其他的则不会被编译，这个应用程序将会以运行大量的解释代码来结束。\n这是当使用 client 编译器模式或分层编译时很频繁的一个问题。当使用普通 server 编译器模式时，编译合格的类的数量将被填入代码缓存，通常只有少量的类会被编译。但是当使用 client 编译器模式时，编译合格的类的数量将会高很多。\n在 Java 7 版本，分层编译默认的代码缓存大小经常是不够的，需要经常提高代码缓存大小。大型项目若使用 client 编译器模式，则也需要提高代码缓存大小。\n现在并没有一个好的机制可以确定一个特定的应用到底需要多大的代码缓存。因此，当需要提高代码缓存时，这将是一种凑巧的操作，一个通常的做法是将代码缓存变成默认大小的两倍或四倍。\n可以通过 –XX:ReservedCodeCacheSize=Nflag（N 就是之前提到的默认大小）来最大化代码缓存大小。代码缓存的管理类似于 JVM 中的内存管理：有一个初始大小（用-XX:InitialCodeCacheSize=N 来声明）。代码缓存的大小从初始大小开始，随着缓存被填满而逐渐扩大。代码缓存的初始大小是基于芯片架构（例如 Intel 系列机器，client 编译器模式下代码缓存大小起始于 160KB，server 编译器模式下代码缓存大小则起始于 2496KB）以及使用的编译器的。重定义代码缓存的大小并不会真正影响性能，所以设置 ReservedCodeCacheSize 的大小一般是必要的。\n再者，如果 JVM 是 32 位的，那么运行过程大小不能超过 4GB。这包括了 Java 堆，JVM 自身所有的代码空间（包括其本身的库和线程栈），应用程序分配的任何的本地内存，当然还有代码缓存。\n所以说代码缓存并不是无限的，很多时候需要为大型应用程序来调优（或者甚至是使用分层编译的中型应用程序）。比如 64 位机器，为代码缓存设置一个很大的值并不会对应用程序本身造成影响，应用程序并不会内存溢出，这些额外的内存预定一般都是被操作系统所接受的。\n编译阈值 在 JVM 中，编译是基于两个计数器的：一个是方法被调用的次数，另一个是方法中循环被回弹执行的次数。回弹可以有效的被认为是循环被执行完成的次数，不仅因为它是循环的结尾，也可能是因为它执行到了一个分支语句，例如 continue。\n当 JVM 执行一个 Java 方法，它会检查这两个计数器的总和以决定这个方法是否有资格被编译。如果有，则这个方法将排队等待编译。这种编译形式并没有一个官方的名字，但是一般被叫做标准编译。\n但是如果方法里有一个很长的循环或者是一个永远都不会退出并提供了所有逻辑的程序会怎么样呢？这种情况下，JVM 需要编译循环而并不等待方法被调用。所以每执行完一次循环，分支计数器都会自增和自检。如果分支计数器计数超出其自身阈值，那么这个循环（并不是整个方法）将具有被编译资格。\n这种编译叫做栈上替换（OSR），因为即使循环被编译了，这也是不够的：JVM 必须有能力当循环正在运行时，开始执行此循环已被编译的版本。换句话说，当循环的代码被编译完成，若 JVM 替换了代码（前栈），那么循环的下个迭代执行最新的被编译版本则会更加快。\n标准编译是被-XX:CompileThreshold=Nflag 的值所触发。Client 编译器模式下，N 默认的值 1500，而 Server 编译器模式下，N 默认的值则是 10000。改变 CompileThreshold 标志的值将会使编译器相对正常情况下提前（或推迟）编译代码。在性能领域，改变 CompileThreshold 标志是很被推荐且流行的方法。事实上，您可能知道 Java 基准经常使用此标志（比如：对于很多 server 编译器来说，经常在经过 8000 次迭代后改变次标志）。\n我们已经知道 client 编译器和 server 编译器在最终的性能上有很大的差别，很大程度上是因为编译器在编译一个特定的方法时，对于两种编译器可用的信息并不一样。降低编译阈值，尤其是对于 server 编译器，承担着不能使应用程序运行达到最佳性能的风险，但是经过测试应用程序我们也发现，将阈值从 8000 变成 10000，其实有着非常小的区别和影响。\n检查编译过程 中级优化的最后一点其实并不是优化本身，而是它们并不能提高应用程序的性能。它们是 JVM（以及其他工具）的各个标志，并可以给出编译工作的可见性。它们中最重要的就是\u0026ndash;XX:+PrintCompilation（默认状态下是 false）。\n如果 PrintCompilation 被启用，每次一个方法（或循环）被编译，JVM 都会打印出刚刚编译过的相关信息。不同的 Java 版本输出形式不一样，我们这里所说的是基于 Java 7 版本的。\n编译日志中大部分的行信息都是下面的形式：\n清单 2. 日志形式\ntimestamp compilation_id attributes (tiered_level) method_name size depot 这里 timestamp 是编译完成时的时间戳，compilation_id 是一个内部的任务 ID，且通常情况下这个数字是单调递增的，但有时候对于 server 编译器（或任何增加编译阈值的时候），您可能会看到失序的编译 ID。这表明编译线程之间有些快有些慢，但请不要随意推断认为是某个编译器任务莫名其妙的非常慢。\n用 jstat 命令检查编译 要想看到编译日志，则需要程序以-XX:+PrintCompilation flag 启动。如果程序启动时没有 flag，您可以通过 jstat 命令得到有限的可见性信息。\nJstat 有两个选项可以提供编译器信息。其中，-compile 选项提供总共有多少方法被编译的总结信息（下面 6006 是要被检查的程序的进程 ID）：\n清单 3 进程详情\n% jstat -compiler 6006 CompiledFailedInvalid TimeFailedTypeFailedMethod 206 0 0 1.97 0 注意，这里也列出了编译失败的方法的个数信息，以及编译失败的最后一个方法的名称。\n另一种选择，您可以使用-printcompilation 选项得到最后一个被编译的方法的编译信息。因为 jstat 命令有一个参数选项用来重复其操作，您可以观察每一次方法被编译的情况。举个例子：\nJstat 对 6006 号 ID 进程每 1000 毫秒执行一次： %jstat –printcompilation 6006 1000，具体的输出信息在此不再描述。\n高级编译器调优 这一节我们将介绍编译工作剩下的细节，并且过程中我们会探讨一些额外的调优策略。调优的存在很大程度上帮助了 JVM 工程师诊断 JVM 自身的行为。如果您对编译器的工作原理很感兴趣，这一节您一定会喜欢。\n编译线程 从前文中我们知道，当一个方法（或循环）拥有编译资格时，它就会排队并等待编译。这个队列是由一个或很多个后台线程组成。这也就是说编译是一个异步的过程。它允许程序在代码正在编译时被继续执行。如果一个方法被标准编译方式所编译，那么下一个方法调用则会执行已编译的方法。如果一个循环被栈上替换方式所编译，那么下一次循环迭代则会执行新编译的代码。\n这些队列并不会严格的遵守先进先出原则：哪一个方法的调用计数器计数更高，哪一个就拥有优先权。所以即使当一个程序开始执行，并且有大量的代码需要编译，这个优先权顺序将帮助并保证最重要的代码被优先编译（这也是为什么编译 ID 在 PrintComilation 的输出结果中有时会失序的另一个原因）。\n当使用 client 编译器时，JVM 启动一个编译线程，而 server 编译器有两个这样的线程。当分层编译生效时，JVM 会基于某些复杂方程式默认启动多个 client 和 server 线程，涉及双日志在目标平台上的 CPU 数量。如下图所示：\n分层编译下 C1 和 C2 编译器线程默认数量：\n图 3. C1 和 C2 编译器默认数量\n编译器线程的数量可以通过-XX:CICompilerCount=N flag 进行调节设置。这个数量是 JVM 将要执行队列所用的线程总数。对于分层编译，三分之一的（至少一个）线程被用于执行 client 编译器队列，剩下的（也是至少一个）被用来执行 server 编译器队列。\n在何时我们应该考虑调整这个值呢？如果一个程序被运行在单 CPU 机器上，那么只有一个编译线程会更好一些：因为对于某个线程来说，其对 CPU 的使用是有限的，并且在很多情况下越少的线程竞争资源会使其运行性能更高。然而，这个优势仅仅局限于初始预热阶段，之后，这些具有编译资格的方法并不会真的引起 CPU 争用。当一个股票批处理应用程序运行在单 CPU 机器上并且编译器线程被限制成只有一个，那么最初的计算过程将比一般情况下快 10%（因为它没有被其他线程进行 CPU 争用）。迭代运行的次数越多，最初的性能收益就相对越少，直到所有的热点方法被编译完性能收益也随之终止。\n结束语 本文详细介绍了 JIT 编译器的工作原理。从优化的角度讲，最简单的选择就是使用 server 编译器的分层编译技术，这将解决大约 90%左右的与编译器直接相关的性能问题。最后，请保证代码缓存的大小设置的足够大，这样编译器将会提供最高的编译性能。\n","id":19,"section":"posts","summary":"转自:https://www.ibm.com/developerworks/cn/java/j-lo-just-in-time/ JIT 简介 JIT 是 just","tags":["jvm","java"],"title":"深入浅出 JIT 编译器","uri":"https://fhxisdog.github.io/2019/04/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-jit-%E7%BC%96%E8%AF%91%E5%99%A8/","year":"2019"}],"tags":[{"title":"android","uri":"https://fhxisdog.github.io/tags/android/"},{"title":"docker","uri":"https://fhxisdog.github.io/tags/docker/"},{"title":"emacs","uri":"https://fhxisdog.github.io/tags/emacs/"},{"title":"flutter","uri":"https://fhxisdog.github.io/tags/flutter/"},{"title":"Git","uri":"https://fhxisdog.github.io/tags/git/"},{"title":"i3wm","uri":"https://fhxisdog.github.io/tags/i3wm/"},{"title":"java","uri":"https://fhxisdog.github.io/tags/java/"},{"title":"jvm","uri":"https://fhxisdog.github.io/tags/jvm/"},{"title":"linux","uri":"https://fhxisdog.github.io/tags/linux/"},{"title":"manjaro","uri":"https://fhxisdog.github.io/tags/manjaro/"},{"title":"maven","uri":"https://fhxisdog.github.io/tags/maven/"},{"title":"modmap","uri":"https://fhxisdog.github.io/tags/modmap/"},{"title":"nacos","uri":"https://fhxisdog.github.io/tags/nacos/"},{"title":"orther","uri":"https://fhxisdog.github.io/tags/orther/"},{"title":"shadowsocks","uri":"https://fhxisdog.github.io/tags/shadowsocks/"},{"title":"skywalking","uri":"https://fhxisdog.github.io/tags/skywalking/"},{"title":"smb","uri":"https://fhxisdog.github.io/tags/smb/"},{"title":"smicroservices","uri":"https://fhxisdog.github.io/tags/smicroservices/"},{"title":"spring boot","uri":"https://fhxisdog.github.io/tags/spring-boot/"},{"title":"spring cloud","uri":"https://fhxisdog.github.io/tags/spring-cloud/"},{"title":"vpn","uri":"https://fhxisdog.github.io/tags/vpn/"},{"title":"vue","uri":"https://fhxisdog.github.io/tags/vue/"}]}